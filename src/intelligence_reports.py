"""
æƒ…æŠ¥æŠ¥å‘Šç”Ÿæˆå™¨ (Intelligence Report Generator)
åŸºäºå¯ŒåŒ–åçš„å¸–å­æ•°æ®ï¼Œç”Ÿæˆé«˜è´¨é‡çš„æƒ…æŠ¥åˆ†ææŠ¥å‘Š
æ”¯æŒå¤šæ¨¡å‹å¹¶è¡Œç”Ÿæˆå’Œ Notion æ¨é€
å‚è€ƒ info-collector-jk é¡¹ç›®çš„é«˜çº§æ¶æ„
"""
import logging
import json
import asyncio
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime, timezone, timedelta
import re

from .database import DatabaseManager
from .llm_client import get_llm_client
from .config import config
from .notion_client import x_intelligence_notion_client
from .scoring import calculate_value_score

logger = logging.getLogger(__name__)


class IntelligenceReportGenerator:
    """æƒ…æŠ¥æŠ¥å‘Šç”Ÿæˆå™¨ï¼Œæ”¯æŒå¤šæ¨¡å‹å¹¶è¡Œç”Ÿæˆå’Œ Notion æ¨é€"""

    def __init__(self, db_manager: Optional[DatabaseManager] = None):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨"""
        if db_manager is not None:
            self.db_manager = db_manager
        else:
            self.db_manager = DatabaseManager(config)

        self.llm_client = get_llm_client()
        if not self.llm_client:
            raise RuntimeError("LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆæƒ…æŠ¥æŠ¥å‘Š")

        # è·å–LLMé…ç½®
        llm_config = config.get_llm_config()
        self.max_content_length = int(llm_config.get('max_content_length', 380000))
        self.max_llm_concurrency = 3  # å¹¶å‘æ¨¡å‹æ•°é‡é™åˆ¶

        # è·å–è¯„åˆ†é…ç½®
        self.scoring_config = config.get_scoring_config()

        analysis_config = config.get_analysis_config()
        context_mode = (analysis_config.get('interpretation_mode') if analysis_config else 'light') or 'light'
        if not isinstance(context_mode, str):
            context_mode = 'light'
        context_mode = context_mode.lower()
        if context_mode not in {'light', 'full'}:
            logger.warning(f"æœªçŸ¥interpretation_modeé…ç½®: {context_mode}, å›é€€åˆ°lightæ¨¡å¼")
            context_mode = 'light'
        self.context_mode = context_mode

        # è·å–æ’é™¤æ ‡ç­¾é…ç½®
        self.exclude_tags = analysis_config.get('exclude_tags', []) if analysis_config else []

        logger.info(f"æƒ…æŠ¥æŠ¥å‘Šç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆï¼Œcontext_mode={self.context_mode}, exclude_tags={self.exclude_tags}")

    def _log_task_start(self, task_type: str, **kwargs) -> None:
        """ç»Ÿä¸€çš„ä»»åŠ¡å¼€å§‹æ—¥å¿—è®°å½•"""
        details = ", ".join([f"{k}={v}" for k, v in kwargs.items()])
        logger.info(f"å¼€å§‹æ‰§è¡Œ {task_type} ä»»åŠ¡: {details}")

    def _log_task_complete(self, task_type: str, success_count: int, failure_count: int, **kwargs) -> None:
        """ç»Ÿä¸€çš„ä»»åŠ¡å®Œæˆæ—¥å¿—è®°å½•"""
        status = "æˆåŠŸ" if failure_count == 0 else f"éƒ¨åˆ†æˆåŠŸ"
        details = ", ".join([f"{k}={v}" for k, v in kwargs.items()])
        logger.info(f"{task_type} ä»»åŠ¡å®Œæˆ ({status}): æˆåŠŸ {success_count} ä¸ªï¼Œå¤±è´¥ {failure_count} ä¸ªã€‚{details}")

    def _handle_task_exception(self, task_type: str, model_name: str, display_name: str, exception: Exception) -> Dict[str, Any]:
        """ç»Ÿä¸€çš„ä»»åŠ¡å¼‚å¸¸å¤„ç†"""
        error_msg = str(exception)
        logger.warning(f"{task_type} ä»»åŠ¡å¼‚å¸¸ - æ¨¡å‹ {model_name} ({display_name}): {error_msg}")
        return {
            'model': model_name,
            'model_display': display_name,
            'success': False,
            'error': error_msg,
            'error_type': type(exception).__name__
        }

    def _create_error_response(self, error_msg: str, **additional_fields) -> Dict[str, Any]:
        """åˆ›å»ºæ ‡å‡†åŒ–çš„é”™è¯¯å“åº”"""
        response = {
            'success': False,
            'error': error_msg,
            'items_analyzed': 0
        }
        response.update(additional_fields)
        return response

    def _bj_time(self) -> datetime:
        """è·å–åŒ—äº¬æ—¶é—´"""
        return datetime.now(timezone.utc) + timedelta(hours=8)

    def _get_report_models(self) -> List[str]:
        """è·å–ç”¨äºç”ŸæˆæŠ¥å‘Šçš„æ¨¡å‹åˆ—è¡¨"""
        if not self.llm_client:
            return []

        models: List[str] = []

        # å…ˆå°è¯•ä» llm_client çš„ report_models å±æ€§è·å–
        raw_models = getattr(self.llm_client, 'report_models', None) or []
        for model_name in raw_models:
            if model_name and model_name not in models:
                models.append(model_name)

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ¨¡å‹åˆ—è¡¨ï¼Œä½¿ç”¨åŸºç¡€å’Œä¼˜å…ˆæ¨¡å‹
        if not models:
            base_model = getattr(self.llm_client, 'smart_model', None)
            priority_model = getattr(self.llm_client, 'priority_model', None)

            if base_model:
                models.append(base_model)
            if priority_model and priority_model not in models:
                models.insert(0, priority_model)

        return models

    def _clean_image_urls_from_content(self, content: str, media_count: int = 0) -> str:
        """
        æ¸…ç†å¸–å­å†…å®¹ä¸­çš„å›¾ç‰‡ URLï¼Œæ›¿æ¢ä¸ºç®€çŸ­è¯´æ˜

        Args:
            content: åŸå§‹å¸–å­å†…å®¹
            media_count: å›¾ç‰‡æ•°é‡ï¼ˆä» media_urls å­—æ®µè·å–ï¼‰

        Returns:
            æ¸…ç†åçš„å†…å®¹
        """
        if not content:
            return ""

        # åŒ¹é… markdown å›¾ç‰‡è¯­æ³•ï¼š![...](...) æˆ– ![](...)
        # ä»¥åŠå•ç‹¬çš„ https://pbs.twimg.com/... URL
        import re

        # ç»Ÿè®¡å¹¶ç§»é™¤ markdown å›¾ç‰‡
        markdown_img_pattern = r'!\[.*?\]\(https://pbs\.twimg\.com/[^\)]+\)'
        found_markdown = re.findall(markdown_img_pattern, content)

        # ç§»é™¤æ‰€æœ‰ markdown å›¾ç‰‡
        cleaned = re.sub(markdown_img_pattern, '', content)

        # ç§»é™¤ç‹¬ç«‹çš„å›¾ç‰‡ URL è¡Œ
        img_url_pattern = r'https://pbs\.twimg\.com/media/[^\s\n]+'
        cleaned = re.sub(img_url_pattern, '', cleaned)

        # æ¸…ç†å¤šä½™çš„ç©ºè¡Œï¼ˆä¿ç•™æœ€å¤šä¸€ä¸ªç©ºè¡Œï¼‰
        cleaned = re.sub(r'\n{3,}', '\n\n', cleaned)
        cleaned = cleaned.strip()

        # åœ¨å†…å®¹å¼€å¤´æ·»åŠ ç®€çŸ­çš„å›¾ç‰‡è¯´æ˜
        if media_count > 0:
            img_note = f"[é™„{media_count}å¼ å›¾]"
            cleaned = f"{img_note}\n{cleaned}"

        return cleaned

    def _get_model_display_name(self, model_name: str) -> str:
        """æ ¹æ®æ¨¡å‹åç§°ç”Ÿæˆç”¨äºå±•ç¤ºçš„å‹å¥½åç§°"""
        if not model_name:
            return 'LLM'

        lower_name = model_name.lower()
        if 'gemini' in lower_name:
            return 'Gemini'
        if 'deepseek' in lower_name:
            return 'DeepSeek'
        if 'grok' in lower_name:
            return 'Grok'
        # GLMæ¨¡å‹è¯†åˆ«ï¼šé€šç”¨æå–ç‰ˆæœ¬å·ï¼ˆå¦‚GLM-4.5ã€GLM-4.6ã€GLM-4vç­‰ï¼‰
        if 'glm' in lower_name:
            # åŒ¹é… GLM-æ•°å­—.æ•°å­— æˆ– GLM-æ•°å­—v ç­‰æ ¼å¼
            match = re.search(r'glm[- ]?(\d+\.?\d*v?)', lower_name)
            if match:
                version = match.group(1)
                return f'GLM{version}'
            else:
                return 'GLM'
        if 'gpt' in lower_name:
            return 'GPT'
        if 'claude' in lower_name:
            return 'Claude'

        return model_name

    def format_enriched_posts_for_smart_llm(self, enriched_posts: List[Dict[str, Any]]) -> Tuple[str, List[Dict[str, Any]]]:
        """
        ä¸ºSmart LLMæ ¼å¼åŒ–å¯ŒåŒ–åçš„å¸–å­æ•°æ®
        åªåŒ…å«æ ¸å¿ƒå†…å®¹ä»¥å‹ç¼©ä¸Šä¸‹æ–‡

        Args:
            enriched_posts: å¯ŒåŒ–åçš„å¸–å­æ•°æ®åˆ—è¡¨

        Returns:
            (æ ¼å¼åŒ–åçš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸², æºæ˜ å°„åˆ—è¡¨)
        """
        context_parts = []
        sources = []
        total_chars = 0

        for i, post_data in enumerate(enriched_posts, 1):
            sid = f"T{i}"

            # åŸºç¡€ä¿¡æ¯
            raw_user_handle = post_data.get('user_id') or 'unknown'
            user_handle = str(raw_user_handle).lstrip('@') or 'unknown'
            post_url = post_data.get('post_url') or 'æœªçŸ¥'

            # æ ¸å¿ƒå†…å®¹
            original_content = post_data.get('post_content') or ''
            has_media = self._post_has_media(post_data)

            # è®¡ç®—å›¾ç‰‡æ•°é‡
            media_count = 0
            if has_media:
                media_urls = post_data.get('media_urls')
                if media_urls:
                    try:
                        if isinstance(media_urls, str):
                            parsed = json.loads(media_urls)
                        else:
                            parsed = media_urls
                        if isinstance(parsed, list):
                            media_count = len(parsed)
                    except (json.JSONDecodeError, TypeError):
                        pass

            # æ¸…ç†å›¾ç‰‡ URLï¼Œå‹ç¼©ä¸Šä¸‹æ–‡
            original_content = self._clean_image_urls_from_content(original_content, media_count)

            include_deep = not (self.context_mode == 'light' and not has_media)

            deep_interpretation = ''
            if include_deep:
                deep_interpretation = (post_data.get('deep_interpretation') or '').strip()
                if not deep_interpretation:
                    deep_interpretation = "æ— æ·±åº¦æ´å¯Ÿ"

            # æ‹¼æ¥åŸå¸–å’Œè§£æ
            if include_deep:
                block = f"[{sid} @{user_handle}]\n{original_content}\nâ†’ æ´å¯Ÿ: {deep_interpretation}"
            else:
                block = f"[{sid} @{user_handle}]\n{original_content}"

            # æ£€æŸ¥é•¿åº¦é™åˆ¶
            if total_chars + len(block) > self.max_content_length:
                logger.info(f"è¾¾åˆ°æœ€å¤§å†…å®¹é™åˆ¶({self.max_content_length}),æˆªæ–­å¸–å­åˆ—è¡¨äºç¬¬ {i-1} æ¡")
                break

            context_parts.append(block)
            total_chars += len(block)

            # æ·»åŠ åˆ°æºæ˜ å°„ï¼Œç”¨äºåç»­ç”Ÿæˆæ¥æºæ¸…å•
            # å³ä½¿ä¸Šä¸‹æ–‡ç®€åŒ–äº†ï¼Œæ¥æºæ¸…å•ä¾ç„¶éœ€è¦è¿™äº›ä¿¡æ¯
            llm_summary = post_data.get('llm_summary', 'æ— æ‘˜è¦')
            sources.append({
                'sid': sid,
                'title': self._truncate(llm_summary or original_content, 100),
                'link': post_url,
                'nickname': user_handle,
                'excerpt': self._truncate(original_content, 120)
            })

        return "\n\n---\n\n".join(context_parts), sources

    def _truncate(self, text: str, max_len: int) -> str:
        """æˆªæ–­æ–‡æœ¬ï¼Œä¿æŒå¯è¯»æ€§"""
        if not text:
            return ""
        if len(text) <= max_len:
            return text
        t = text[:max_len]
        # å°è¯•åœ¨å¥å°¾æˆªæ–­
        for d in ['ã€‚', '!', '?', '.', '!', '?', '\n']:
            pos = t.rfind(d)
            if pos > max_len * 0.7:
                return t[:pos + 1] + "\n..."
        return t + "\n..."

    def _post_has_media(self, post_data: Dict[str, Any]) -> bool:
        """åˆ¤æ–­å¸–å­æ˜¯å¦åŒ…å«åª’ä½“å†…å®¹"""
        has_media_flag = post_data.get('has_media')
        if has_media_flag is not None:
            try:
                return bool(int(has_media_flag))
            except (ValueError, TypeError):
                return bool(has_media_flag)

        media_urls = post_data.get('media_urls')
        if not media_urls:
            return False

        if isinstance(media_urls, str):
            try:
                parsed = json.loads(media_urls)
            except (json.JSONDecodeError, TypeError):
                return False
        elif isinstance(media_urls, list):
            parsed = media_urls
        else:
            return False

        if isinstance(parsed, list):
            return len(parsed) > 0

        return False

    def get_light_report_prompt(self, formatted_context: str, time_range: str) -> str:
        """
        æ„å»º"æ—¥æŠ¥èµ„è®¯"æç¤ºè¯ï¼ˆå…¨é¢ä¿¡æ¯æµå¼çš„ç®€æŠ¥ï¼‰
        å¼ºè°ƒå…¨é¢æ€§å’Œåˆ†ç±»èšåˆ
        """
        prompt_template = f"""# Role: ä¸–ç•Œä¸€æµçš„ç§‘æŠ€èµ„è®¯ç¼–è¾‘ï¼Œæ“…é•¿å¿«é€Ÿæç‚¼å…³é”®ä¿¡æ¯å¹¶åˆ†ç±»å‘ˆç°

# Context:
ä½ æ­£åœ¨ä¸ºå¿™ç¢Œçš„ç§‘æŠ€ä»ä¸šè€…ç¼–å†™ä¸€ä»½æ¯æ—¥å¿«è®¯ã€‚è¯»è€…å¸Œæœ›åœ¨æœ€çŸ­æ—¶é—´å†…è·å–{time_range}å†…å…¨çƒç§‘æŠ€é¢†åŸŸçš„é‡è¦åŠ¨æ€ã€‚ä½ æ”¶åˆ°çš„æ˜¯ç»è¿‡ç­›é€‰çš„X/TwitteræŠ€æœ¯é¢†è¢–å‘å¸ƒçš„å¸–å­ã€‚

# Core Principles:
1. **å…¨é¢è¦†ç›– (Comprehensive Coverage)**: å°½å¯èƒ½æ¶µç›–æ‰€æœ‰æœ‰ä»·å€¼çš„ä¿¡æ¯ç‚¹ï¼Œä¸é—æ¼é‡è¦åŠ¨æ€ã€‚
2. **åˆ†ç±»æ¸…æ™° (Clear Categorization)**: æŒ‰ä¸»é¢˜åˆ†ç±»ç»„ç»‡ä¿¡æ¯ï¼Œä¾¿äºå¿«é€ŸæŸ¥æ‰¾ã€‚
3. **è¯¦ç•¥å¾—å½“ (Appropriate Detail)**: æ¯æ¡ä¿¡æ¯éƒ½åº”æä¾›è¶³å¤Ÿä¸Šä¸‹æ–‡ï¼Œç¡®ä¿è¯»è€…èƒ½ç†è§£å…¶æ ¸å¿ƒä»·å€¼ã€‚é¿å…è¿‡åº¦å‹ç¼©ï¼Œä½†ä¿æŒç²¾ç‚¼ã€‚
4. **å¯è¿½æº¯æ€§ (Traceability)**: æ¯æ¡ä¿¡æ¯å¿…é¡»æ ‡æ³¨æ¥æº `[Source: T_n]`ã€‚

# Input Data Format:
ä½ å°†æ”¶åˆ°ä¸€ç³»åˆ—å¸–å­ï¼Œæ ¼å¼ä¸ºï¼š
- çº¯æ–‡æœ¬å¸–ï¼š`[T_id @user_handle]` + å¸–å­å†…å®¹
- å›¾æ–‡å¸–ï¼š`[T_id @user_handle]` + å¸–å­å†…å®¹ + `â†’ æ´å¯Ÿ: {{AIè§£è¯»}}`

# Your Task:
ç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„æ—¥æŠ¥èµ„è®¯ï¼Œä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹Markdownæ ¼å¼ã€‚è¯·ä¸ºæ¯æ¡èµ„è®¯æä¾›è¯¦å®ã€æ¸…æ™°çš„æè¿°ã€‚

## ğŸ“° ä»Šæ—¥è¦é—»
*æœ¬èŠ‚æ±‡æ€»æœ€é‡è¦çš„5-15æ¡æ ¸å¿ƒæ–°é—»*
- **[æ–°é—»æ ‡é¢˜]**: ç®€è¦æè¿°ï¼Œè¯´æ¸…æ¥šæ–°é—»æ ¸å¿ƒå†…å®¹ (50-200å­—) [Source: T_n]

---

## ğŸ”¥ çƒ­é—¨è¯é¢˜
*æŒ‰è¯é¢˜åˆ†ç±»ç»„ç»‡è®¨è®ºçƒ­ç‚¹*

### è¯é¢˜A: [è¯é¢˜åç§°]
- **[æ ¸å¿ƒè§‚ç‚¹]**: å¯¹è§‚ç‚¹çš„æ¸…æ™°é˜è¿°ï¼Œè¯´æ˜å…¶èƒŒæ™¯å’Œé‡è¦æ€§ (50-200å­—) [Source: T_n]
- **[æ ¸å¿ƒè§‚ç‚¹]**: ... [Source: T_m]

### è¯é¢˜B: [è¯é¢˜åç§°]
- **[æ ¸å¿ƒè§‚ç‚¹]**: ... [Source: T_x]

---

## ğŸ’¡ æŠ€æœ¯åŠ¨æ€
*æ–°æŠ€æœ¯ã€æ–°åŠŸèƒ½ã€æŠ€æœ¯è®¨è®º*
- **[æŠ€æœ¯ç‚¹]**: è¯¦ç»†è¯´æ˜å…¶èƒŒæ™¯ã€æ ¸å¿ƒå†…å®¹å’Œæ½œåœ¨å½±å“ (50-200å­—) [Source: T_n]

---

## ğŸš€ äº§å“å‘å¸ƒ
*æ–°äº§å“ã€æ–°åŠŸèƒ½å‘å¸ƒ*
- **[äº§å“å]**: ä»‹ç»å…¶æ ¸å¿ƒç‰¹æ€§ã€ç›®æ ‡ç”¨æˆ·å’Œå¸‚åœºååº” (50-200å­—) [Source: T_n]

---

## ğŸ› ï¸ å·¥å…·èµ„æº
*æœ‰ä»·å€¼çš„å·¥å…·ã€åº“ã€æ•™ç¨‹*
- **[èµ„æºå]**: è¯¦ç»†è¯´æ˜å…¶ç”¨é€”ã€ç‰¹ç‚¹å’Œæ¨èç†ç”± (50-200å­—) [Source: T_n]

---

## ğŸ“Š è¡Œä¸šè§‚å¯Ÿ
*è¡Œä¸šè¶‹åŠ¿ã€å•†ä¸šåˆ†æã€å¸‚åœºåŠ¨æ€*
- **[è§‚å¯Ÿç‚¹]**: é˜è¿°å…³é”®ä¿¡æ¯ã€æ•°æ®å’Œä½ çš„è§£è¯» (50-200å­—) [Source: T_n]

---

## ğŸ¯ ç²¾é€‰è§‚ç‚¹
*å€¼å¾—å…³æ³¨çš„ç‹¬ç‰¹è§è§£*
- **[@ç”¨æˆ·]**: æ¸…æ™°é˜è¿°å…¶æ ¸å¿ƒè§‚ç‚¹ã€è®ºæ®å’Œå¯å‘æ„ä¹‰ (50-200å­—) [Source: T_n]

# Input Data:
```
{formatted_context}
```

# Important Notes:
1. æ¯ä¸ªåˆ†ç±»è‡³å°‘è¦æœ‰3-5æ¡ä¿¡æ¯ï¼Œå¦‚æœæŸåˆ†ç±»æ— å†…å®¹å¯çœç•¥è¯¥åˆ†ç±»ã€‚
2. **ä¿¡æ¯è¦å…¨é¢**ï¼Œä¸è¦é—æ¼æœ‰ä»·å€¼çš„å†…å®¹ã€‚
3. æ¯æ¡ä¿¡æ¯å¿…é¡»æœ‰ `[Source: T_n]` æ ‡æ³¨ã€‚
4. **å†…å®¹ä¸ºç‹**: ç¡®ä¿æ¯æ¡ä¿¡æ¯çš„æè¿°è¶³å¤Ÿæ¸…æ™°ã€å®Œæ•´ï¼Œèƒ½å¤Ÿç‹¬ç«‹æˆæ–‡ã€‚å¯¹äºå¤æ‚æˆ–é‡è¦çš„åŠ¨æ€ï¼Œå®å¯ç¯‡å¹…ç¨é•¿ï¼Œä¹Ÿè¦è¯´æ¸…æ¥šæ¥é¾™å»è„‰å’Œæ ¸å¿ƒä»·å€¼ã€‚
"""
        return prompt_template

    def get_intelligence_report_prompt(
        self,
        formatted_context: str,
        time_range: str,
        context_mode: Optional[str] = None
    ) -> str:
        """
        æ„å»ºæƒ…æŠ¥åˆ†ææŠ¥å‘Šçš„æç¤ºè¯ã€‚
        æç¤ºè¯å†…å®¹ç›´æ¥å†…è”åœ¨æ­¤å‡½æ•°ä¸­ï¼Œä»¥å‡å°‘å¤–éƒ¨æ–‡ä»¶ä¾èµ–ã€‚
        """
        normalized_mode = (context_mode or getattr(self, 'context_mode', 'light') or 'light').lower()
        if normalized_mode not in {'light', 'full'}:
            normalized_mode = 'light'

        # å®šä¹‰ç²¾ç¡®çš„æ•°æ®æ ¼å¼æè¿°ï¼Œä»¥åŒ¹é… format_enriched_posts_for_smart_llm çš„è¾“å‡º
        # è¿™éƒ¨åˆ†å†…å®¹æ—¨åœ¨å‘ŠçŸ¥LLMå…¶æ¥æ”¶åˆ°çš„`formatted_context`ä¸­æ¯ä¸ªå¸–å­çš„è¯¦ç»†ç»“æ„
        if normalized_mode == 'light':
            accurate_data_format_description = """# Input Data Format:
ä½ å°†æ”¶åˆ°ä¸€ç³»åˆ—ç»è¿‡é¢„å¤„ç†çš„å¸–å­ï¼Œé‡‡ç”¨ç´§å‡‘æ ¼å¼ä»¥ä¼˜åŒ–ä¸Šä¸‹æ–‡ã€‚æ¯æ¡å¸–å­åŒ…å«åŸå§‹æ–‡æœ¬å†…å®¹ï¼›åªæœ‰å½“å¸–å­åŒ…å«å›¾ç‰‡æˆ–å¤šåª’ä½“æ—¶ï¼Œæ‰ä¼šé¢å¤–é™„å¸¦æ·±åº¦æ´å¯Ÿã€‚

**æ ¼å¼è¯´æ˜**ï¼š
- çº¯æ–‡æœ¬å¸–ï¼š`[T_id @user_handle]` + æ¢è¡Œ + å¸–å­åŸæ–‡
- å›¾æ–‡å¸–ï¼š`[T_id @user_handle]` + æ¢è¡Œ + å¸–å­åŸæ–‡ + æ¢è¡Œ + `â†’ æ´å¯Ÿ: {AIç”Ÿæˆçš„ç»¼åˆè§£è¯»}`

**é‡è¦**ï¼š
1. T_id æ˜¯æ¥æºæ ‡è¯†ç¬¦ï¼Œä½ åœ¨åˆ†æä¸­å¼•ç”¨æ—¶ä½¿ç”¨ `[Source: T_id]` æ ¼å¼
2. å¯¹äºçº¯æ–‡æœ¬å¸–ï¼Œè¯·ç›´æ¥åŸºäºåŸæ–‡è¿›è¡Œåˆ†æ
3. å¯¹äºå›¾æ–‡å¸–ï¼Œè¯·ç»¼åˆåŸæ–‡å’Œæ´å¯Ÿå†…å®¹è¿›è¡Œåˆ†æ"""
        else:
            accurate_data_format_description = """# Input Data Format:
ä½ å°†æ”¶åˆ°ä¸€ç³»åˆ—ç»è¿‡é¢„å¤„ç†çš„å¸–å­ï¼Œé‡‡ç”¨ç´§å‡‘æ ¼å¼ä»¥ä¼˜åŒ–ä¸Šä¸‹æ–‡ã€‚æ¯æ¡å¸–å­éƒ½åŒ…å«åŸå§‹å†…å®¹å’ŒAIç”Ÿæˆçš„æ·±åº¦æ´å¯Ÿã€‚

**æ ¼å¼è¯´æ˜**ï¼š
`[T_id @user_handle]` + æ¢è¡Œ + å¸–å­åŸæ–‡ + æ¢è¡Œ + `â†’ æ´å¯Ÿ: {LLMç”Ÿæˆçš„æ·±åº¦è§£è¯»}`

**é‡è¦**ï¼š
1. T_id æ˜¯æ¥æºæ ‡è¯†ç¬¦ï¼Œä½ åœ¨åˆ†æä¸­å¼•ç”¨æ—¶ä½¿ç”¨ `[Source: T_id]` æ ¼å¼
2. è¯·ç»¼åˆåˆ©ç”¨åŸæ–‡å’Œæ´å¯Ÿä¸¤éƒ¨åˆ†ä¿¡æ¯è¿›è¡Œåˆ†æ
3. æ´å¯Ÿéƒ¨åˆ†æ˜¯AIå¯¹å¸–å­çš„æ·±åº¦è§£è¯»ï¼Œæ˜¯ä½ åˆ†æçš„æ ¸å¿ƒä¾æ®"""

        # æ ¸å¿ƒæç¤ºè¯æ¨¡æ¿
        prompt_template = f"""# Role: ä¸–ç•Œé¡¶çº§çš„æŠ€æœ¯ä¸é£é™©æŠ•èµ„åˆ†æå¸ˆï¼Œæ‹¥æœ‰ã€Šç»æµå­¦äººã€‹çš„ç¼–è¾‘ä¸¥è°¨åº¦å’Œã€ŠStratecheryã€‹çš„å‰ç»æ€§æ´å¯ŸåŠ›ã€‚

# Context:
ä½ æ­£åœ¨ä¸ºä¸€ä»½å…¨çƒé¡¶çº§æŠ€æœ¯ä¸“å®¶ã€åˆ›å§‹äººä¸VCåˆä¼™äººé˜…è¯»çš„å†…å‚æ’°å†™æŠ¥å‘Šã€‚ä»–ä»¬æ—¶é—´å®è´µï¼Œæåº¦å…³æ³¨"ä¿¡å·"ï¼ŒåŒæ¶"å™ªéŸ³"ã€‚ä½ æ”¶åˆ°çš„åŸå§‹ææ–™æ˜¯{time_range}å†…ï¼Œç”±æˆ‘ä»¬ç²¾å¿ƒç­›é€‰çš„å…¨çƒæŠ€æœ¯æ€æƒ³é¢†è¢–åœ¨X/Twitterä¸Šå‘å¸ƒçš„å¸–å­ï¼Œå¹¶ç»è¿‡äº†åˆæ­¥çš„AIæ´å¯Ÿå¤„ç†ã€‚

# Core Principles:
1.  **æ·±åº¦ä¸ä»·å€¼ä¼˜å…ˆ (Depth & Value First)**: ä½ çš„æ ¸å¿ƒç›®æ ‡æ˜¯æŒ–æ˜å‡ºå¯¹ä»ä¸šè€…æœ‰ç›´æ¥ä»·å€¼çš„ä¿¡æ¯ã€‚åœ¨æ’°å†™æ¯ä¸ªéƒ¨åˆ†æ—¶ï¼Œéƒ½åº”è¿½æ±‚å†…å®¹çš„**æ·±åº¦å’Œå®Œæ•´æ€§**ï¼Œ**é¿å…è¿‡äºç®€çŸ­çš„æ¦‚æ‹¬**ã€‚
2.  **æ·±åº¦åˆæˆ (Deep Synthesis)**: ä¸è¦ç®€å•ç½—åˆ—ã€‚ä½ éœ€è¦å°†ä¸åŒæ¥æºçš„ä¿¡æ¯ç‚¹è¿æ¥èµ·æ¥ï¼Œæ„å»ºæˆæœ‰æ„ä¹‰çš„å™äº‹ï¼ˆNarrativeï¼‰ã€‚
3.  **æ³¨å…¥æ´è§ (Inject Insight)**: ä½ ä¸æ˜¯ä¸€ä¸ªæ€»ç»“è€…ï¼Œè€Œæ˜¯ä¸€ä¸ªåˆ†æå¸ˆã€‚åœ¨é™ˆè¿°äº‹å®å’Œè§‚ç‚¹çš„åŸºç¡€ä¸Šï¼Œ**å¿…é¡»**åŠ å…¥ä½ è‡ªå·±çš„ã€åŸºäºä¸Šä¸‹æ–‡çš„ã€æœ‰æ·±åº¦çš„åˆ†æå’Œè¯„è®ºã€‚
4.  **ç»å¯¹å¯è¿½æº¯ (Absolute Traceability)**: ä½ çš„æ¯ä¸€æ¡æ´å¯Ÿã€åˆ¤æ–­å’Œå»ºè®®ï¼Œéƒ½å¿…é¡»åœ¨å¥æœ«ä½¿ç”¨ `[Source: T_n]` æˆ– `[Sources: T_n, T_m]` çš„æ ¼å¼æ˜ç¡®æ ‡æ³¨ä¿¡æ¯æ¥æºã€‚è¿™æ˜¯ç¡¬æ€§è¦æ±‚,ç»å¯¹ä¸èƒ½é—æ¼ã€‚

{accurate_data_format_description}

# Your Task:
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹äº”ä¸ªå±‚æ¬¡çš„åˆ†ææ¡†æ¶ï¼Œç”Ÿæˆä¸€ä»½**å†…å®¹ä¸°å¯Œè¯¦å®ã€ä¿¡æ¯å¯†åº¦æé«˜ã€æ´å¯Ÿæ·±åˆ»**çš„å®Œæ•´Markdownæƒ…æŠ¥æŠ¥å‘Šã€‚

**ç¬¬ä¸€å±‚æ¬¡ï¼šåŠ¨æ€ä¸çƒ­ç‚¹æ¦‚è§ˆ (Dynamics & Hotspot Overview)**
*   **1.1 åŠ¨æ€æ‘˜è¦**: å†™ä¸€ä¸ª300å­—å·¦å³çš„"æ‰§è¡Œæ‘˜è¦"ï¼Œæ€»ç»“å‘¨æœŸå†…æœ€é‡è¦çš„åŠ¨æ€å’Œæœ€å…³é”®çš„ä¿¡å·ã€‚
*   **1.2 æ ¸å¿ƒè¯é¢˜**: è¯†åˆ«å‡ºæœ¬å‘¨æœŸå†…æ‰€æœ‰å€¼å¾—å…³æ³¨çš„æ ¸å¿ƒè¯é¢˜ï¼ˆä¸å°‘äº5ä¸ªï¼‰ã€‚å¯¹æ¯ä¸ªè¯é¢˜ï¼Œ**è¯¦ç»†é˜è¿°**å…¶æ ¸å¿ƒè®®é¢˜ï¼Œå¹¶**å°½å¯èƒ½å…¨é¢åœ°**åˆ—å‡ºæœ€å…·ä»£è¡¨æ€§çš„è§‚ç‚¹å’Œè®¨è®ºæ–¹å‘ã€‚

**ç¬¬äºŒå±‚æ¬¡ï¼šè§‚ç‚¹å¯¹æ’åœ†æ¡Œ (Perspectives Collision Round-table)**
*   ä»»åŠ¡ï¼šå›´ç»•æœ¬å‘¨æœŸå†…æœ€å…·äº‰è®®æ€§æˆ–å¤šé¢æ€§çš„è¯é¢˜ï¼Œç»„ç»‡1åœºè™šæ‹Ÿåœ†æ¡Œè®¨è®ºã€‚
*   è¦æ±‚ï¼š
    1.  **è®¾å®šè®®é¢˜**: æ˜ç¡®æœ¬åœºåœ†æ¡Œçš„æ ¸å¿ƒè®®é¢˜ã€‚
    2.  **é‚€è¯·å˜‰å®¾**: ä»æ•°æ®ä¸­æŒ‘é€‰æŒæœ‰ä¸åŒï¼ˆç”šè‡³å¯¹ç«‹ï¼‰è§‚ç‚¹çš„ç”¨æˆ·ä½œä¸º"è™šæ‹Ÿå˜‰å®¾"ã€‚
    3.  **å‘ˆç°è§‚ç‚¹**: æ¸…æ™°åœ°å±•ç¤ºæ¯ä½å˜‰å®¾çš„æ ¸å¿ƒè®ºç‚¹ï¼Œå¹¶ç›´æ¥å¼•ç”¨å…¶åŸæ–‡ç²¾åã€‚
    4.  **åˆ†æå¸ˆç‚¹è¯„ (å…³é”®ï¼)**: åœ¨æ‰€æœ‰è§‚ç‚¹é™ˆè¿°å®Œæ¯•åï¼Œ**åŠ å…¥ä½ è‡ªå·±çš„ã€ç¯‡å¹…å……è¶³çš„åˆ†æå¸ˆç‚¹è¯„**ã€‚ç‚¹è¯„å†…å®¹åº”åŒ…æ‹¬ä½†ä¸é™äºï¼šæŒ‡å‡ºå„æ–¹è§‚ç‚¹çš„ç›²åŒºã€ç‚¹æ˜äº‰è®®çš„æœ¬è´¨ã€é¢„æµ‹è¯¥è®®é¢˜çš„æœªæ¥èµ°å‘ã€æˆ–è€…æå‡ºä¸€ä¸ªæ›´é«˜ç»´åº¦çš„ç»¼åˆæ€§çœ‹æ³•ã€‚
    5.  **å¤‡é€‰æ–¹æ¡ˆ**: å¦‚æœæœ¬å‘¨æœŸå†…æ²¡æœ‰æ˜æ˜¾å¯¹ç«‹çš„è§‚ç‚¹ï¼Œè¯·é€‰æ‹©ä¸€ä¸ªæ ¸å¿ƒè¯é¢˜ï¼Œ**æ·±å…¥å‰–æ**å…¶ä¸åŒè§’åº¦ï¼ˆå¦‚å¼€å‘è€…ã€äº§å“ç»ç†ã€ç”¨æˆ·ï¼‰çš„è®ºè¿°ï¼Œæˆ–å°†å…¶æ”¹ä¸ºå¯¹ä¸€ä¸ªå…³é”®äººç‰©æ ¸å¿ƒè§‚ç‚¹çš„æ·±åº¦å‰–æã€‚

**ç¬¬ä¸‰å±‚æ¬¡ï¼šè¶‹åŠ¿ä¸å™äº‹æ·±åº¦åˆ†æ (Trend & Narrative Analysis)**
*   **3.1 è¶‹åŠ¿/ä¿¡å·**: è¯†åˆ«æ‰€æœ‰çƒ­åº¦é«˜æˆ–è€…è®¨è®ºåº¦å¿«é€Ÿä¸Šå‡çš„"è¶‹åŠ¿"æˆ–"å¾®å¼±ä¿¡å·"ã€‚**è¯¦ç»†æè¿°**å®ƒæ˜¯ä»€ä¹ˆï¼Œä¸ºä»€ä¹ˆå®ƒç°åœ¨å‡ºç°ï¼Œä»¥åŠå®ƒå¯èƒ½å¯¹è¡Œä¸šäº§ç”Ÿä»€ä¹ˆå½±å“ã€‚**ä¸è¦å±€é™äºå°‘æ•°å‡ ç‚¹**ã€‚
*   **3.2 å®å¤§å™äº‹**: å¯»æ‰¾ä¸åŒè¯é¢˜ä¹‹é—´çš„å†…åœ¨è”ç³»ï¼Œæ„å»ºä¸€ä¸ªæˆ–å¤šä¸ªå®å¤§å™äº‹ã€‚**è¯¦ç»†å±•å¼€**è¿™ä¸ªå™äº‹ï¼Œä¾‹å¦‚ï¼Œå°†"æ–°AIæ¨¡å‹çš„å‘å¸ƒ"ã€"å¼€æºç¤¾åŒºçš„è®¨è®º"å’Œ"ä¸‹æ¸¸åº”ç”¨çš„æ¢ç´¢"è”ç³»èµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªå…³äº"XXXæŠ€æœ¯ä»ç†è®ºåˆ°å®è·µçš„æ¼”è¿›è·¯å¾„"çš„å®Œæ•´å™äº‹ã€‚

**ç¬¬å››å±‚æ¬¡ï¼šç²¾é€‰èµ„æºåº“ (Curated Resource Library)**
*   ä»»åŠ¡ï¼šä»æœ¬å‘¨æœŸæ‰€æœ‰åˆ†äº«çš„é“¾æ¥ä¸­ï¼Œç²¾é€‰å‡º**æ‰€æœ‰å…·å¤‡é«˜ä»·å€¼**çš„èµ„æºï¼Œå°½å¯èƒ½å¤šï¼Œä¸è¦åªå±€é™äºå‡ ä¸ªã€‚
*   è¦æ±‚ï¼š
    *   **4.1 æ•™ç¨‹ä¸æŒ‡å—**: æŒ‘é€‰å‡ºæ‰€æœ‰æœ‰ä»·å€¼çš„æ•™ç¨‹ã€æŒ‡å—æˆ–æ·±åº¦å­¦ä¹ ç¬”è®°ã€‚
    *   **4.2 å·¥å…·ä¸é¡¹ç›®**: æŒ‘é€‰å‡ºæ‰€æœ‰å€¼å¾—å…³æ³¨çš„æ–°å·¥å…·æˆ–å¼€æºé¡¹ç›®ã€‚
    *   å¯¹æ¯ä¸ªå…¥é€‰çš„èµ„æºï¼Œ**ç”¨ä¸€æ®µè¯è¯¦ç»†è¯´æ˜**å…¶æ ¸å¿ƒä»·å€¼å’Œæ¨èç†ç”±ï¼Œè€Œä¸ä»…ä»…æ˜¯ä¸€å¥è¯æ¦‚æ‹¬ã€‚

**ç¬¬äº”å±‚æ¬¡ï¼šè§’è‰²åŒ–è¡ŒåŠ¨å»ºè®® (Role-Based Actionable Recommendations)**
*   ä»»åŠ¡ï¼šå°†æ‰€æœ‰åˆ†æè½¬åŒ–ä¸ºå¯¹ç‰¹å®šè§’è‰²çš„ã€**ä¸°å¯Œä¸”å…·ä½“**çš„ã€å¯ç«‹å³æ‰§è¡Œçš„å»ºè®®ã€‚
*   è¦æ±‚ï¼šå»ºè®®å¿…é¡»å…·ä½“ã€æ–°é¢–ä¸”å…·æœ‰å‰ç»æ€§ï¼Œå¹¶é˜è¿°å…¶èƒŒåçš„é€»è¾‘ã€‚
    *   **ç»™å¼€å‘è€…çš„å»ºè®®**: [ä¾‹å¦‚ï¼šå»ºè®®ç«‹å³ç ”ç©¶ `XXX` æ¡†æ¶ï¼Œå› ä¸ºå®ƒåœ¨è§£å†³ `YYY` é—®é¢˜ä¸Šè¡¨ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚ç¤¾åŒºè®¨è®ºè¡¨æ˜...] [Source: T_n]
    *   **ç»™äº§å“ç»ç†/åˆ›ä¸šè€…çš„å»ºè®®**: [ä¾‹å¦‚ï¼šç¤¾åŒºå¯¹ `ZZZ` åœºæ™¯çš„éœ€æ±‚åå¤å‡ºç°ï¼Œä½†ç°æœ‰è§£å†³æ–¹æ¡ˆå‡æœ‰ç¼ºé™·ï¼Œè¿™å¯èƒ½æ˜¯ä¸€ä¸ªè¢«å¿½è§†çš„è“æµ·å¸‚åœºã€‚å…·ä½“è¡¨ç°ä¸º...] [Source: T_m]
    *   **ç»™æŠ•èµ„è€…çš„å»ºè®®**: [ä¾‹å¦‚ï¼š`AAA` é¢†åŸŸçš„è®¨è®ºçƒ­åº¦ä¸æŠ€æœ¯æˆç†Ÿåº¦å‡ºç°"å…±æŒ¯"ï¼Œå¯èƒ½é¢„ç¤ºç€å•†ä¸šåŒ–æ‹ç‚¹å³å°†åˆ°æ¥ã€‚å…³é”®ä¿¡å·åŒ…æ‹¬...] [Source: T_k]
    *   ...(è¯·ä¸ºæ¯ä¸ªè§’è‰²æä¾›**å°½å¯èƒ½å¤š**çš„æœ‰ä»·å€¼å»ºè®®)

# Output Format (Strictly follow this Markdown structure):

## ä¸€ã€åŠ¨æ€ä¸çƒ­ç‚¹æ¦‚è§ˆ
### 1.1 åŠ¨æ€æ‘˜è¦
[æ‰§è¡Œæ‘˜è¦å†…å®¹]
### 1.2 æ ¸å¿ƒè¯é¢˜
*   **è¯é¢˜A**: [è¯¦ç»†é˜è¿°]
    *   è§‚ç‚¹1: [å†…å®¹] [Source: T_n]
    *   è§‚ç‚¹2: [å†…å®¹] [Source: T_m]
    *   ... (æ›´å¤šè§‚ç‚¹)
*   **è¯é¢˜B**: ...
*   ... (æ›´å¤šè¯é¢˜)

---

## äºŒã€è§‚ç‚¹å¯¹æ’åœ†æ¡Œï¼š[è®®é¢˜åç§°]
### å˜‰å®¾è§‚ç‚¹
*   **æ­£æ–¹ä»£è¡¨ (`@user_handle_1`)**: [è§‚ç‚¹é™ˆè¿°] [Source: T_a]
*   **åæ–¹ä»£è¡¨ (`@user_handle_2`)**: [è§‚ç‚¹é™ˆè¿°] [Source: T_b]
*   **ä¸­ç«‹/æŠ€æœ¯æ´¾ (`@user_handle_3`)**: [è§‚ç‚¹é™ˆè¿°] [Source: T_c]
### åˆ†æå¸ˆç‚¹è¯„
[ä½ å¯¹è¿™åœºè¾©è®ºçš„æ€»ç»“ã€æ´å¯Ÿå’Œæ›´é«˜ç»´åº¦çš„ã€ç¯‡å¹…å……è¶³çš„åˆ†æ...]

---

## ä¸‰ã€è¶‹åŠ¿ä¸å™äº‹åˆ†æ
### 3.1 å‘å±•è¶‹åŠ¿ï¼š[è¶‹åŠ¿åç§°]
[è¯¦ç»†æè¿°è¯¥è¶‹åŠ¿...] [Sources: T_d, T_e]
...(è¯¦å°½çš„æ›´å¤šè¶‹åŠ¿)
### 3.2 å®å¤§å™äº‹ï¼š[å™äº‹åç§°]
[è¯¦ç»†æè¿°è¯¥å™äº‹...] [Sources: T_f, T_g]
...(è¯¦å°½çš„æ›´å¤šå™äº‹)

---

## å››ã€ç²¾é€‰èµ„æºåº“
### 4.1 æ•™ç¨‹ä¸æŒ‡å—
*   **[èµ„æºåç§°]**: [è¯¦ç»†æ¨èç†ç”±] [Source: T_h]
*   ... (è¯¦å°½çš„æ›´å¤šèµ„æº)
### 4.2 å·¥å…·ä¸é¡¹ç›®
*   **[èµ„æºåç§°]**: [è¯¦ç»†æ¨èç†ç”±] [Source: T_i]
*   ... (è¯¦å°½çš„æ›´å¤šèµ„æº)

---

## äº”ã€è§’è‰²åŒ–è¡ŒåŠ¨å»ºè®®
*   **To å¼€å‘è€…**:
    * [å»ºè®®å†…å®¹] [Source: T_j]
    * ... (è¯¦å°½çš„æ›´å¤šå»ºè®®)
*   **To äº§å“ç»ç†/åˆ›ä¸šè€…**:
    * [å»ºè®®å†…å®¹] [Source: T_k]
    * ... (è¯¦å°½çš„æ›´å¤šå»ºè®®)
*   **To æŠ•èµ„è€…/ç ”ç©¶è€…**:
    * [å»ºè®®å†…å®¹] [Source: T_l]
    * ... (è¯¦å°½çš„æ›´å¤šå»ºè®®)

# Input Data:
```
{formatted_context}
```
"""

        return prompt_template

    async def _generate_report_for_model(
        self,
        *,
        model_name: str,
        display_name: str,
        enriched_posts: List[Dict[str, Any]],
        context_md: str,
        sources: List[Dict[str, Any]],
        prompt: str,
        start_time: datetime,
        end_time: datetime
    ) -> Dict[str, Any]:
        """åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­ç”ŸæˆæŒ‡å®šæ¨¡å‹çš„æŠ¥å‘Š"""
        return await asyncio.to_thread(
            self._generate_report_for_model_sync,
            model_name,
            display_name,
            enriched_posts,
            context_md,
            sources,
            prompt,
            start_time,
            end_time
        )

    def _generate_report_for_model_sync(
        self,
        model_name: str,
        display_name: str,
        enriched_posts: List[Dict[str, Any]],
        context_md: str,
        sources: List[Dict[str, Any]],
        prompt: str,
        start_time: datetime,
        end_time: datetime
    ) -> Dict[str, Any]:
        """åŒæ­¥æ‰§è¡ŒæŒ‡å®šæ¨¡å‹çš„æŠ¥å‘Šç”Ÿæˆå’ŒNotionæ¨é€"""

        logger.info(f"[{display_name}] æ¨¡å‹çº¿ç¨‹å¯åŠ¨ï¼Œå¼€å§‹ç”Ÿæˆæƒ…æŠ¥æŠ¥å‘Š")

        # è°ƒç”¨LLMç”ŸæˆæŠ¥å‘Š
        try:
            response = self.llm_client.call_smart_model(prompt, model_override=model_name, temperature=0.4)

            if not response or not response.get('success'):
                error_msg = f"LLMè°ƒç”¨å¤±è´¥: {response.get('error') if response else 'Unknown error'}"
                logger.warning(f"[{display_name}] {error_msg}")
                return {
                    'success': False,
                    'error': error_msg,
                    'model': model_name,
                    'model_display': display_name
                }

            llm_output = response.get('content', '')
        except Exception as e:
            error_msg = f"LLMè°ƒç”¨å¼‚å¸¸: {str(e)}"
            logger.error(f"[{display_name}] {error_msg}")
            return {
                'success': False,
                'error': error_msg,
                'model': model_name,
                'model_display': display_name
            }

        # ä¸ºLLMç”Ÿæˆçš„æŠ¥å‘Šæ·»åŠ æ ‡å‡†å¤´éƒ¨ä¿¡æ¯
        beijing_time = self._bj_time()
        header_info = [
            f"# ğŸ“Š X/Twitter æŠ€æœ¯æƒ…æŠ¥æ—¥æŠ¥ - {display_name}",
            "",
            f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {beijing_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
            "",
            f"*æ•°æ®èŒƒå›´: {start_time.strftime('%Y-%m-%d %H:%M:%S')} - {end_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
            "",
            f"*åˆ†æåŠ¨æ€æ•°: {len(enriched_posts)} æ¡*",
            "",
            "---",
            ""
        ]

        # æ¸…ç†LLMè¾“å‡ºä¸­å¯èƒ½çš„æ ¼å¼é—®é¢˜
        cleaned_llm_output = self._clean_llm_output_for_notion(llm_output)

        sources_section = self._render_sources_section(sources)

        # æ„å»ºæŠ¥å‘Šå°¾éƒ¨
        footer_lines = ["", "---", ""]
        provider = response.get('provider')
        model = response.get('model')
        if provider:
            footer_lines.append(f"*åˆ†æå¼•æ“: {provider} ({model or 'unknown'})*")

        footer_lines.extend([
            "",
            f"ğŸ“Š **ç»Ÿè®¡æ‘˜è¦**: æœ¬æŠ¥å‘Šåˆ†æäº† {len(enriched_posts)} æ¡åŠ¨æ€",
            "",
            "*æœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ*"
        ])
        footer_section = "\n".join(footer_lines)

        report_content = "\n".join(header_info) + cleaned_llm_output + "\n\n" + sources_section + footer_section

        # åº”ç”¨æ¥æºé“¾æ¥å¢å¼ºåå¤„ç†
        report_content = self._enhance_source_links(report_content, sources)

        title = f"X/Twitter æŠ€æœ¯æƒ…æŠ¥æ—¥æŠ¥ - {display_name} - {end_time.strftime('%Y-%m-%d %H:%M')}"

        # ä¿å­˜æŠ¥å‘Šåˆ°æ•°æ®åº“
        try:
            if self.db_manager.save_intelligence_report(
                'daily',
                title,
                report_content,
                start_time,
                end_time
            ):
                logger.info(f"[{display_name}] æƒ…æŠ¥æŠ¥å‘Šå·²æˆåŠŸä¿å­˜åˆ°æ•°æ®åº“")
            else:
                logger.warning(f"[{display_name}] æŠ¥å‘Šä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥")
        except Exception as e:
            logger.error(f"[{display_name}] ä¿å­˜æŠ¥å‘Šåˆ°æ•°æ®åº“æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")

        model_report = {
            'model': model_name,
            'model_display': display_name,
            'success': True,
            'report_title': title,
            'report_content': report_content,
            'provider': response.get('provider') if response else None,
            'items_analyzed': len(enriched_posts)
        }

        # å°è¯•æ¨é€åˆ°Notion
        notion_push_info = None
        try:
            # æ ¼å¼åŒ–Notionæ ‡é¢˜
            beijing_time = self._bj_time()
            time_str = beijing_time.strftime('%H:%M')
            notion_title = f"[{time_str}] [{display_name}] XæŠ€æœ¯æƒ…æŠ¥æ—¥æŠ¥ ({len(enriched_posts)}æ¡åŠ¨æ€)"

            logger.info(f"å¼€å§‹æ¨é€æƒ…æŠ¥æŠ¥å‘Šåˆ°Notion ({display_name}): {notion_title}")

            notion_result = x_intelligence_notion_client.create_report_page(
                report_title=notion_title,
                report_content=report_content,
                report_date=beijing_time
            )

            if notion_result.get('success'):
                logger.info(f"æƒ…æŠ¥æŠ¥å‘ŠæˆåŠŸæ¨é€åˆ°Notion ({display_name}): {notion_result.get('page_url')}")
                notion_push_info = {
                    'success': True,
                    'page_url': notion_result.get('page_url'),
                    'path': notion_result.get('path')
                }
            else:
                error_msg = notion_result.get('error', 'æœªçŸ¥é”™è¯¯')
                logger.warning(f"æ¨é€æƒ…æŠ¥æŠ¥å‘Šåˆ°Notionå¤±è´¥ ({display_name}): {error_msg}")
                notion_push_info = {
                    'success': False,
                    'error': error_msg
                }

        except Exception as e:
            logger.warning(f"æ¨é€æƒ…æŠ¥æŠ¥å‘Šåˆ°Notionæ—¶å‡ºé”™ ({display_name}): {e}")
            notion_push_info = {
                'success': False,
                'error': str(e)
            }

        if notion_push_info:
            model_report['notion_push'] = notion_push_info

        return model_report

    def _clean_llm_output_for_notion(self, llm_output: str) -> str:
        """æ¸…ç†LLMè¾“å‡ºå†…å®¹ï¼Œç¡®ä¿Notionå…¼å®¹æ€§"""
        if not llm_output:
            return ""

        # ä¿æŠ¤Sourceå¼•ç”¨æ ¼å¼ï¼Œä¸è¦æ›¿æ¢å…¶ä¸­çš„æ–¹æ‹¬å·
        import re

        # å…ˆæå–æ‰€æœ‰Sourceå¼•ç”¨
        source_pattern = r'\[Sources?:\s*[T\d\s,]+\]'
        sources = re.findall(source_pattern, llm_output)

        # ä¸´æ—¶æ›¿æ¢Sourceå¼•ç”¨ä¸ºå ä½ç¬¦
        temp_llm_output = llm_output
        source_placeholders = {}
        for i, source in enumerate(sources):
            placeholder = f"__SOURCE_PLACEHOLDER_{i}__"
            source_placeholders[placeholder] = source
            temp_llm_output = temp_llm_output.replace(source, placeholder)

        # æ›¿æ¢å…¶ä»–å¯èƒ½å¯¼è‡´Markdowné“¾æ¥å†²çªçš„æ–¹æ‹¬å·
        cleaned = temp_llm_output.replace('[', 'ã€').replace(']', 'ã€‘')

        # æ¢å¤Sourceå¼•ç”¨
        for placeholder, original_source in source_placeholders.items():
            cleaned = cleaned.replace(placeholder, original_source)

        # ç¡®ä¿è¡Œå°¾æœ‰é€‚å½“çš„ç©ºæ ¼ç”¨äºæ¢è¡Œ
        lines = cleaned.split('\n')
        processed_lines = []

        for line in lines:
            # å¯¹äºä»¥*å¼€å¤´çš„æ–œä½“è¡Œï¼Œåœ¨è¡Œå°¾æ·»åŠ ç©ºæ ¼ä»¥ç¡®ä¿æ¢è¡Œ
            if line.strip().startswith('*') and line.strip().endswith('*'):
                processed_lines.append(line.rstrip() + '  ')
            else:
                processed_lines.append(line)

        return '\n'.join(processed_lines)

    def _render_sources_section(self, sources: List[Dict[str, Any]]) -> str:
        """æ¸²æŸ“æ¥æºæ¸…å•éƒ¨åˆ†"""
        if not sources:
            return ""

        lines = ["## ğŸ“š æ¥æºæ¸…å• (Source List)", ""]
        for s in sources:
            # æ¸…ç†æ ‡é¢˜ä¸­çš„æ–¹æ‹¬å·ï¼Œé¿å…ä¸Markdowné“¾æ¥å†²çª
            clean_title = (s.get('title') or s.get('excerpt') or '').replace('[', 'ã€').replace(']', 'ã€‘')
            nickname = s.get('nickname') or ''
            if nickname:
                nickname_display = f"@{nickname}"
            else:
                nickname_display = ""

            link = s.get('link')
            if link:
                actor_part = f"[{nickname_display}]({link})" if nickname_display else f"[æ¥æº]({link})"
            else:
                actor_part = nickname_display or "æ¥æº"

            lines.append(f"- **ã€{s.get('sid')}ã€‘**: {actor_part}: {clean_title}")
        return "\n".join(lines)

    def _enhance_source_links(self, report_content: str, sources: List[Dict[str, Any]]) -> str:
        """
        å¢å¼ºæŠ¥å‘Šä¸­çš„æ¥æºé“¾æ¥ï¼Œå°† [Source: T1, T2] ä¸­çš„æ¯ä¸ª Txx è½¬æ¢ä¸ºå¯ç‚¹å‡»çš„é“¾æ¥
        """
        import re

        # æ„å»ºæ¥æºIDåˆ°é“¾æ¥çš„æ˜ å°„
        source_link_map = {s['sid']: s['link'] for s in sources}

        def replace_source_refs(match):
            # æå–å®Œæ•´çš„ Source å¼•ç”¨å†…å®¹
            full_source_text = match.group(0)  # å¦‚ "[Source: T2, T9, T18]"
            source_content = match.group(1)    # å¦‚ "T2, T9, T18"

            # åˆ†å‰²å¹¶å¤„ç†æ¯ä¸ªæ¥æºID
            source_ids = [sid.strip() for sid in source_content.split(',')]
            linked_sources = []

            for sid in source_ids:
                if sid in source_link_map:
                    # å°† Txx è½¬æ¢ä¸ºé“¾æ¥
                    linked_sources.append(f"[{sid}]({source_link_map[sid]})")
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°å¯¹åº”é“¾æ¥ï¼Œä¿æŒåŸæ ·
                    linked_sources.append(sid)

            # é‡æ–°ç»„åˆ
            return f"ğŸ“ [Source: {', '.join(linked_sources)}]"

        # æŸ¥æ‰¾æ‰€æœ‰ [Source: ...] æˆ– [Sources: ...] æ¨¡å¼å¹¶æ›¿æ¢
        pattern = r'\[Sources?:\s*([T\d\s,]+)\]'
        enhanced_content = re.sub(pattern, replace_source_refs, report_content)

        return enhanced_content

    def _fetch_and_score_posts(self, start_time: datetime, end_time: datetime, limit: int, candidate_multiplier: Optional[float] = None) -> List[Dict[str, Any]]:
        """è·å–å¹¶æ ¹æ®ä»·å€¼åˆ†ç­›é€‰å¸–å­"""
        # ç¡®å®šå€™é€‰æ± å¤§å°
        if candidate_multiplier is None:
            candidate_multiplier = self.scoring_config.get('candidate_multiplier', 3)

        candidate_limit = int(limit * candidate_multiplier)

        logger.info(f"æ­£åœ¨è·å–å€™é€‰å¸–å­æ±  (limit={limit}, multiplier={candidate_multiplier}, candidate_limit={candidate_limit})")

        # è·å–æ›´å¤§çš„å€™é€‰æ± 
        candidate_posts = self.db_manager.get_enriched_posts_for_report(
            start_time,
            end_time,
            candidate_limit,
            context_mode=self.context_mode,
            exclude_tags=self.exclude_tags
        )

        if not candidate_posts:
            logger.warning("å€™é€‰æ± ä¸ºç©º")
            return []

        logger.info(f"è·å–åˆ° {len(candidate_posts)} æ¡å€™é€‰å¸–å­ï¼Œå¼€å§‹è®¡ç®—ä»·å€¼åˆ†...")

        # è®¡ç®—ä»·å€¼åˆ†
        for post in candidate_posts:
            post['value_score'] = calculate_value_score(post, self.scoring_config)

        # æ’åº: ä¼˜å…ˆæŒ‰ä»·å€¼åˆ†é™åºï¼Œæ¬¡ä¼˜å…ˆæŒ‰å‘å¸ƒæ—¶é—´é™åº (Tie-breaker)
        candidate_posts.sort(key=lambda p: (p.get('value_score', 0), p.get('published_at')), reverse=True)

        # æˆªå– Top N
        final_posts = candidate_posts[:limit]

        # è®°å½•ä¸€ä¸‹æœ€é«˜åˆ†å’Œæœ€ä½åˆ†ä»¥ä¾¿è°ƒè¯•
        if final_posts:
            highest = final_posts[0].get('value_score')
            lowest = final_posts[-1].get('value_score')
            logger.info(f"ç­›é€‰å®Œæˆ: {len(final_posts)} æ¡ã€‚æœ€é«˜åˆ†: {highest}, æœ€ä½å…¥é€‰åˆ†: {lowest}")

        return final_posts

    async def generate_intelligence_report(self, hours: int = 24, limit: int = 300, candidate_multiplier: Optional[float] = None) -> Dict[str, Any]:
        """
        ç”Ÿæˆæƒ…æŠ¥åˆ†ææŠ¥å‘Šï¼Œæ”¯æŒå¤šæ¨¡å‹å¹¶è¡Œç”Ÿæˆ

        Args:
            hours: æ—¶é—´èŒƒå›´ï¼ˆå°æ—¶ï¼‰
            limit: æœ€å¤§å¸–å­æ•°é‡
            candidate_multiplier: å€™é€‰æ± å€æ•°

        Returns:
            ç”Ÿæˆç»“æœ
        """
        self._log_task_start("æƒ…æŠ¥æŠ¥å‘Šç”Ÿæˆ", hours=hours, limit=limit, multiplier=candidate_multiplier)

        try:
            # è®¡ç®—æ—¶é—´èŒƒå›´
            end_time = datetime.now()
            start_time = end_time - timedelta(hours=hours)

            # è·å–å¹¶ç­›é€‰å¸–å­
            enriched_posts = self._fetch_and_score_posts(start_time, end_time, limit, candidate_multiplier)

            if not enriched_posts:
                logger.warning(f"åœ¨æŒ‡å®šæ—¶é—´èŒƒå›´å†…æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å¸–å­æ•°æ®")
                return self._create_error_response('æ²¡æœ‰å¯ç”¨çš„å¸–å­æ•°æ®')

            logger.info(f"ç­›é€‰å‡º {len(enriched_posts)} æ¡é«˜ä»·å€¼å¸–å­æ•°æ®ç”¨äºæŠ¥å‘Šç”Ÿæˆ")

            # æ ¼å¼åŒ–ä¸Šä¸‹æ–‡
            formatted_context, sources = self.format_enriched_posts_for_smart_llm(enriched_posts)

            # æ„å»ºæç¤ºè¯
            time_range_str = f"è¿‡å»{hours}å°æ—¶"
            prompt = self.get_intelligence_report_prompt(
                formatted_context,
                time_range_str,
                context_mode=self.context_mode
            )

            logger.info(f"æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")

            # è·å–è¦ä½¿ç”¨çš„æ¨¡å‹åˆ—è¡¨
            models_to_generate = self._get_report_models()
            if not models_to_generate:
                logger.warning("æœªé…ç½®ä»»ä½•å¯ç”¨äºç”ŸæˆæŠ¥å‘Šçš„æ¨¡å‹")
                return self._create_error_response('æœªé…ç½®å¯ç”¨çš„LLMæ¨¡å‹')

            model_reports: List[Dict[str, Any]] = []
            failures: List[Dict[str, Any]] = []
            tasks = []
            task_meta: List[Dict[str, str]] = []

            # ä¸ºæ¯ä¸ªæ¨¡å‹åˆ›å»ºå¹¶è¡Œä»»åŠ¡
            for model_name in models_to_generate:
                display_name = self._get_model_display_name(model_name)
                task_meta.append({'model': model_name, 'display': display_name})
                tasks.append(
                    self._generate_report_for_model(
                        model_name=model_name,
                        display_name=display_name,
                        enriched_posts=enriched_posts,
                        context_md=formatted_context,
                        sources=sources,
                        prompt=prompt,
                        start_time=start_time,
                        end_time=end_time
                    )
                )

            logger.info(
                f"å¼€å§‹å¹¶è¡Œç”Ÿæˆ {len(tasks)} ä»½æƒ…æŠ¥æŠ¥å‘Š: {[meta['display'] for meta in task_meta]}"
            )

            # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
            task_results = await asyncio.gather(*tasks, return_exceptions=True)

            # å¤„ç†ä»»åŠ¡ç»“æœ
            for meta, task_result in zip(task_meta, task_results):
                model_name = meta['model']
                display_name = meta['display']

                if isinstance(task_result, Exception):
                    error_msg = str(task_result)
                    logger.warning(
                        f"æ¨¡å‹ {model_name} ({display_name}) æŠ¥å‘Šç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°æœªå¤„ç†å¼‚å¸¸: {error_msg}"
                    )
                    failures.append({
                        'model': model_name,
                        'model_display': display_name,
                        'error': error_msg
                    })
                    continue

                if task_result.get('success'):
                    model_reports.append(task_result)
                else:
                    failure_entry = {
                        'model': model_name,
                        'model_display': display_name,
                        'error': task_result.get('error', 'æŠ¥å‘Šç”Ÿæˆå¤±è´¥')
                    }
                    failures.append(failure_entry)

            # æ„å»ºæœ€ç»ˆç»“æœ
            overall_success = len(model_reports) > 0
            result = {
                'success': overall_success,
                'items_analyzed': len(enriched_posts) if overall_success else 0,
                'model_reports': model_reports,
                'failures': failures
            }

            if overall_success:
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªæˆåŠŸçš„æŠ¥å‘Šä½œä¸ºä¸»è¦ç»“æœ
                primary_report = model_reports[0]
                result['report_title'] = primary_report['report_title']
                result['report_content'] = primary_report['report_content']
                result['notion_push'] = primary_report.get('notion_push')
                result['time_range'] = f"{start_time.strftime('%Y-%m-%d %H:%M')} - {end_time.strftime('%Y-%m-%d %H:%M')}"

            self._log_task_complete(
                "æƒ…æŠ¥æŠ¥å‘Šç”Ÿæˆ",
                len(model_reports),
                len(failures),
                models=len(models_to_generate)
            )

            return result

        except Exception as e:
            logger.error(f"ç”Ÿæˆæƒ…æŠ¥æŠ¥å‘Šæ—¶å‘ç”Ÿå¼‚å¸¸: {e}", exc_info=True)
            return self._create_error_response(f'ç”Ÿæˆå¼‚å¸¸: {str(e)}')

    async def generate_light_reports(self, hours: int = 24, limit: int = 300, candidate_multiplier: Optional[float] = None) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ—¥æŠ¥èµ„è®¯ï¼ˆLight Reportsï¼‰- å¤šæ¨¡å‹å¹¶è¡Œç”Ÿæˆ

        Args:
            hours: æ—¶é—´èŒƒå›´ï¼ˆå°æ—¶ï¼‰
            limit: æœ€å¤§å¸–å­æ•°é‡
            candidate_multiplier: å€™é€‰æ± å€æ•°

        Returns:
            ç”Ÿæˆç»“æœ
        """
        self._log_task_start("æ—¥æŠ¥èµ„è®¯ç”Ÿæˆ", hours=hours, limit=limit, multiplier=candidate_multiplier)

        try:
            # è®¡ç®—æ—¶é—´èŒƒå›´
            end_time = datetime.now()
            start_time = end_time - timedelta(hours=hours)

            # è·å–å¹¶ç­›é€‰å¸–å­
            enriched_posts = self._fetch_and_score_posts(start_time, end_time, limit, candidate_multiplier)

            if not enriched_posts:
                logger.warning(f"åœ¨æŒ‡å®šæ—¶é—´èŒƒå›´å†…æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å¸–å­æ•°æ®")
                return self._create_error_response('æ²¡æœ‰å¯ç”¨çš„å¸–å­æ•°æ®')

            logger.info(f"ç­›é€‰å‡º {len(enriched_posts)} æ¡é«˜ä»·å€¼å¸–å­æ•°æ®ï¼Œå¼€å§‹ç”Ÿæˆæ—¥æŠ¥èµ„è®¯")

            # æ ¼å¼åŒ–ä¸Šä¸‹æ–‡
            formatted_context, sources = self.format_enriched_posts_for_smart_llm(enriched_posts)

            # æ„å»ºæ—¥æŠ¥èµ„è®¯æç¤ºè¯
            time_range_str = f"è¿‡å»{hours}å°æ—¶"
            prompt = self.get_light_report_prompt(formatted_context, time_range_str)

            logger.info(f"æ—¥æŠ¥èµ„è®¯æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")

            # è·å–è¦ä½¿ç”¨çš„æ¨¡å‹åˆ—è¡¨
            models_to_generate = self._get_report_models()
            if not models_to_generate:
                logger.warning("æœªé…ç½®ä»»ä½•å¯ç”¨äºç”ŸæˆæŠ¥å‘Šçš„æ¨¡å‹")
                return self._create_error_response('æœªé…ç½®å¯ç”¨çš„LLMæ¨¡å‹')

            model_reports: List[Dict[str, Any]] = []
            failures: List[Dict[str, Any]] = []
            tasks = []
            task_meta: List[Dict[str, str]] = []

            # ä¸ºæ¯ä¸ªæ¨¡å‹åˆ›å»ºå¹¶è¡Œä»»åŠ¡
            for model_name in models_to_generate:
                display_name = self._get_model_display_name(model_name)
                task_meta.append({'model': model_name, 'display': display_name})
                tasks.append(
                    self._generate_light_report_for_model(
                        model_name=model_name,
                        display_name=display_name,
                        enriched_posts=enriched_posts,
                        context_md=formatted_context,
                        sources=sources,
                        prompt=prompt,
                        start_time=start_time,
                        end_time=end_time
                    )
                )

            logger.info(f"å¼€å§‹å¹¶è¡Œç”Ÿæˆ {len(tasks)} ä»½æ—¥æŠ¥èµ„è®¯: {[meta['display'] for meta in task_meta]}")

            # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
            task_results = await asyncio.gather(*tasks, return_exceptions=True)

            # å¤„ç†ä»»åŠ¡ç»“æœ
            for meta, task_result in zip(task_meta, task_results):
                model_name = meta['model']
                display_name = meta['display']

                if isinstance(task_result, Exception):
                    error_msg = str(task_result)
                    logger.warning(f"æ¨¡å‹ {model_name} ({display_name}) æ—¥æŠ¥èµ„è®¯ç”Ÿæˆå¼‚å¸¸: {error_msg}")
                    failures.append({
                        'model': model_name,
                        'model_display': display_name,
                        'error': error_msg
                    })
                    continue

                if task_result.get('success'):
                    model_reports.append(task_result)
                else:
                    failures.append({
                        'model': model_name,
                        'model_display': display_name,
                        'error': task_result.get('error', 'æŠ¥å‘Šç”Ÿæˆå¤±è´¥')
                    })

            # æ„å»ºæœ€ç»ˆç»“æœ
            overall_success = len(model_reports) > 0
            result = {
                'success': overall_success,
                'items_analyzed': len(enriched_posts) if overall_success else 0,
                'model_reports': model_reports,
                'failures': failures,
                'report_type': 'light'
            }

            self._log_task_complete(
                "æ—¥æŠ¥èµ„è®¯ç”Ÿæˆ",
                len(model_reports),
                len(failures),
                models=len(models_to_generate)
            )

            return result

        except Exception as e:
            logger.error(f"ç”Ÿæˆæ—¥æŠ¥èµ„è®¯æ—¶å‘ç”Ÿå¼‚å¸¸: {e}", exc_info=True)
            return self._create_error_response(f'ç”Ÿæˆå¼‚å¸¸: {str(e)}')

    async def _generate_light_report_for_model(
        self,
        *,
        model_name: str,
        display_name: str,
        enriched_posts: List[Dict[str, Any]],
        context_md: str,
        sources: List[Dict[str, Any]],
        prompt: str,
        start_time: datetime,
        end_time: datetime
    ) -> Dict[str, Any]:
        """ç”Ÿæˆå•ä¸ªæ¨¡å‹çš„æ—¥æŠ¥èµ„è®¯"""
        return await asyncio.to_thread(
            self._generate_light_report_for_model_sync,
            model_name,
            display_name,
            enriched_posts,
            context_md,
            sources,
            prompt,
            start_time,
            end_time
        )

    def _generate_light_report_for_model_sync(
        self,
        model_name: str,
        display_name: str,
        enriched_posts: List[Dict[str, Any]],
        context_md: str,
        sources: List[Dict[str, Any]],
        prompt: str,
        start_time: datetime,
        end_time: datetime
    ) -> Dict[str, Any]:
        """åŒæ­¥æ‰§è¡Œå•ä¸ªæ¨¡å‹çš„æ—¥æŠ¥èµ„è®¯ç”Ÿæˆå’ŒNotionæ¨é€"""

        logger.info(f"[{display_name}] å¼€å§‹ç”Ÿæˆæ—¥æŠ¥èµ„è®¯")

        # è°ƒç”¨LLMç”ŸæˆæŠ¥å‘Š
        try:
            response = self.llm_client.call_smart_model(prompt, model_override=model_name, temperature=0.3)

            if not response or not response.get('success'):
                error_msg = f"LLMè°ƒç”¨å¤±è´¥: {response.get('error') if response else 'Unknown error'}"
                logger.warning(f"[{display_name}] {error_msg}")
                return {
                    'success': False,
                    'error': error_msg,
                    'model': model_name,
                    'model_display': display_name
                }

            llm_output = response.get('content', '')
        except Exception as e:
            error_msg = f"LLMè°ƒç”¨å¼‚å¸¸: {str(e)}"
            logger.error(f"[{display_name}] {error_msg}")
            return {
                'success': False,
                'error': error_msg,
                'model': model_name,
                'model_display': display_name
            }

        # ä¸ºLLMç”Ÿæˆçš„æŠ¥å‘Šæ·»åŠ æ ‡å‡†å¤´éƒ¨ä¿¡æ¯
        beijing_time = self._bj_time()
        header_info = [
            f"# ğŸ“° X/Twitter æŠ€æœ¯æ—¥æŠ¥èµ„è®¯ - {display_name}",
            "",
            f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {beijing_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
            "",
            f"*æ•°æ®èŒƒå›´: {start_time.strftime('%Y-%m-%d %H:%M:%S')} - {end_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
            "",
            f"*åˆ†æåŠ¨æ€æ•°: {len(enriched_posts)} æ¡*",
            "",
            "---",
            ""
        ]

        # æ¸…ç†LLMè¾“å‡º
        cleaned_llm_output = self._clean_llm_output_for_notion(llm_output)

        sources_section = self._render_sources_section(sources)

        # æ„å»ºæŠ¥å‘Šå°¾éƒ¨
        footer_lines = ["", "---", ""]
        provider = response.get('provider')
        model = response.get('model')
        if provider:
            footer_lines.append(f"*åˆ†æå¼•æ“: {provider} ({model or 'unknown'})*")

        footer_lines.extend([
            "",
            f"ğŸ“Š **ç»Ÿè®¡æ‘˜è¦**: æœ¬æŠ¥å‘Šåˆ†æäº† {len(enriched_posts)} æ¡åŠ¨æ€",
            "",
            "*æœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ*"
        ])
        footer_section = "\n".join(footer_lines)

        report_content = "\n".join(header_info) + cleaned_llm_output + "\n\n" + sources_section + footer_section

        # åº”ç”¨æ¥æºé“¾æ¥å¢å¼º
        report_content = self._enhance_source_links(report_content, sources)

        title = f"XæŠ€æœ¯æ—¥æŠ¥èµ„è®¯ - {display_name} - {end_time.strftime('%Y-%m-%d %H:%M')}"

        # ä¿å­˜æŠ¥å‘Šåˆ°æ•°æ®åº“
        try:
            if self.db_manager.save_intelligence_report(
                'daily_light',
                title,
                report_content,
                start_time,
                end_time
            ):
                logger.info(f"[{display_name}] æ—¥æŠ¥èµ„è®¯å·²æˆåŠŸä¿å­˜åˆ°æ•°æ®åº“")
            else:
                logger.warning(f"[{display_name}] æ—¥æŠ¥èµ„è®¯ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥")
        except Exception as e:
            logger.error(f"[{display_name}] ä¿å­˜æ—¥æŠ¥èµ„è®¯åˆ°æ•°æ®åº“æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")

        model_report = {
            'model': model_name,
            'model_display': display_name,
            'success': True,
            'report_title': title,
            'report_content': report_content,
            'provider': response.get('provider') if response else None,
            'items_analyzed': len(enriched_posts)
        }

        # å°è¯•æ¨é€åˆ°Notionï¼ˆä½¿ç”¨å±‚çº§ç»“æ„ï¼‰
        notion_push_info = None
        try:
            beijing_time = self._bj_time()
            time_str = beijing_time.strftime('%H:%M')
            notion_title = f"[{time_str}] [{display_name}] XæŠ€æœ¯æ—¥æŠ¥ ({len(enriched_posts)}æ¡)"

            logger.info(f"å¼€å§‹æ¨é€æ—¥æŠ¥èµ„è®¯åˆ°Notion ({display_name}): {notion_title}")

            notion_result = x_intelligence_notion_client.create_report_page_in_hierarchy(
                report_title=notion_title,
                report_content=report_content,
                report_date=beijing_time,
                report_type='light'
            )

            if notion_result.get('success'):
                logger.info(f"æ—¥æŠ¥èµ„è®¯æˆåŠŸæ¨é€åˆ°Notion ({display_name}): {notion_result.get('page_url')}")
                notion_push_info = {
                    'success': True,
                    'page_url': notion_result.get('page_url'),
                    'path': notion_result.get('path')
                }
            else:
                error_msg = notion_result.get('error', 'æœªçŸ¥é”™è¯¯')
                logger.warning(f"æ¨é€æ—¥æŠ¥èµ„è®¯åˆ°Notionå¤±è´¥ ({display_name}): {error_msg}")
                notion_push_info = {
                    'success': False,
                    'error': error_msg
                }

        except Exception as e:
            logger.warning(f"æ¨é€æ—¥æŠ¥èµ„è®¯åˆ°Notionæ—¶å‡ºé”™ ({display_name}): {e}")
            notion_push_info = {
                'success': False,
                'error': str(e)
            }

        if notion_push_info:
            model_report['notion_push'] = notion_push_info

        return model_report

    async def generate_deep_report(self, hours: int = 24, limit: int = 300, candidate_multiplier: Optional[float] = None) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ·±åº¦æŠ¥å‘Šï¼ˆDeep Reportï¼‰- å¤šæ¨¡å‹å¹¶è¡Œç”Ÿæˆ

        Args:
            hours: æ—¶é—´èŒƒå›´ï¼ˆå°æ—¶ï¼‰
            limit: æœ€å¤§å¸–å­æ•°é‡
            candidate_multiplier: å€™é€‰æ± å€æ•°

        Returns:
            ç”Ÿæˆç»“æœ
        """
        self._log_task_start("æ·±åº¦æŠ¥å‘Šç”Ÿæˆ", hours=hours, limit=limit, multiplier=candidate_multiplier)

        try:
            # è®¡ç®—æ—¶é—´èŒƒå›´
            end_time = datetime.now()
            start_time = end_time - timedelta(hours=hours)

            # è·å–å¹¶ç­›é€‰å¸–å­
            enriched_posts = self._fetch_and_score_posts(start_time, end_time, limit, candidate_multiplier)

            if not enriched_posts:
                logger.warning(f"åœ¨æŒ‡å®šæ—¶é—´èŒƒå›´å†…æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å¸–å­æ•°æ®")
                return self._create_error_response('æ²¡æœ‰å¯ç”¨çš„å¸–å­æ•°æ®')

            logger.info(f"ç­›é€‰å‡º {len(enriched_posts)} æ¡é«˜ä»·å€¼å¸–å­æ•°æ®ï¼Œå¼€å§‹ç”Ÿæˆæ·±åº¦æŠ¥å‘Š")

            # æ ¼å¼åŒ–ä¸Šä¸‹æ–‡
            formatted_context, sources = self.format_enriched_posts_for_smart_llm(enriched_posts)

            # æ„å»ºæ·±åº¦æŠ¥å‘Šæç¤ºè¯
            time_range_str = f"è¿‡å»{hours}å°æ—¶"
            prompt = self.get_intelligence_report_prompt(
                formatted_context,
                time_range_str,
                context_mode=self.context_mode
            )

            logger.info(f"æ·±åº¦æŠ¥å‘Šæç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")

            # è·å–è¦ä½¿ç”¨çš„æ¨¡å‹åˆ—è¡¨
            models_to_generate = self._get_report_models()
            if not models_to_generate:
                logger.warning("æœªé…ç½®ä»»ä½•å¯ç”¨äºç”ŸæˆæŠ¥å‘Šçš„æ¨¡å‹")
                return self._create_error_response('æœªé…ç½®å¯ç”¨çš„LLMæ¨¡å‹')

            model_reports: List[Dict[str, Any]] = []
            failures: List[Dict[str, Any]] = []
            tasks = []
            task_meta: List[Dict[str, str]] = []

            # ä¸ºæ¯ä¸ªæ¨¡å‹åˆ›å»ºå¹¶è¡Œä»»åŠ¡
            for model_name in models_to_generate:
                display_name = self._get_model_display_name(model_name)
                task_meta.append({'model': model_name, 'display': display_name})
                tasks.append(
                    self._generate_deep_report_for_model(
                        model_name=model_name,
                        display_name=display_name,
                        enriched_posts=enriched_posts,
                        context_md=formatted_context,
                        sources=sources,
                        prompt=prompt,
                        start_time=start_time,
                        end_time=end_time
                    )
                )

            logger.info(f"å¼€å§‹å¹¶è¡Œç”Ÿæˆ {len(tasks)} ä»½æ·±åº¦æŠ¥å‘Š: {[meta['display'] for meta in task_meta]}")

            # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
            task_results = await asyncio.gather(*tasks, return_exceptions=True)

            # å¤„ç†ä»»åŠ¡ç»“æœ
            for meta, task_result in zip(task_meta, task_results):
                model_name = meta['model']
                display_name = meta['display']

                if isinstance(task_result, Exception):
                    error_msg = str(task_result)
                    logger.warning(f"æ¨¡å‹ {model_name} ({display_name}) æ·±åº¦æŠ¥å‘Šç”Ÿæˆå¼‚å¸¸: {error_msg}")
                    failures.append({
                        'model': model_name,
                        'model_display': display_name,
                        'error': error_msg
                    })
                    continue

                if task_result.get('success'):
                    model_reports.append(task_result)
                else:
                    failures.append({
                        'model': model_name,
                        'model_display': display_name,
                        'error': task_result.get('error', 'æŠ¥å‘Šç”Ÿæˆå¤±è´¥')
                    })

            # æ„å»ºæœ€ç»ˆç»“æœ
            overall_success = len(model_reports) > 0
            result = {
                'success': overall_success,
                'items_analyzed': len(enriched_posts) if overall_success else 0,
                'model_reports': model_reports,
                'failures': failures,
                'report_type': 'deep'
            }

            self._log_task_complete(
                "æ·±åº¦æŠ¥å‘Šç”Ÿæˆ",
                len(model_reports),
                len(failures),
                models=len(models_to_generate)
            )

            return result

        except Exception as e:
            logger.error(f"ç”Ÿæˆæ·±åº¦æŠ¥å‘Šæ—¶å‘ç”Ÿå¼‚å¸¸: {e}", exc_info=True)
            return self._create_error_response(f'ç”Ÿæˆå¼‚å¸¸: {str(e)}')

    async def _generate_deep_report_for_model(
        self,
        *,
        model_name: str,
        display_name: str,
        enriched_posts: List[Dict[str, Any]],
        context_md: str,
        sources: List[Dict[str, Any]],
        prompt: str,
        start_time: datetime,
        end_time: datetime
    ) -> Dict[str, Any]:
        """ç”Ÿæˆæ·±åº¦æŠ¥å‘Š"""
        return await asyncio.to_thread(
            self._generate_deep_report_for_model_sync,
            model_name,
            display_name,
            enriched_posts,
            context_md,
            sources,
            prompt,
            start_time,
            end_time
        )

    def _generate_deep_report_for_model_sync(
        self,
        model_name: str,
        display_name: str,
        enriched_posts: List[Dict[str, Any]],
        context_md: str,
        sources: List[Dict[str, Any]],
        prompt: str,
        start_time: datetime,
        end_time: datetime
    ) -> Dict[str, Any]:
        """åŒæ­¥æ‰§è¡Œæ·±åº¦æŠ¥å‘Šç”Ÿæˆå’ŒNotionæ¨é€"""

        logger.info(f"[{display_name}] å¼€å§‹ç”Ÿæˆæ·±åº¦æŠ¥å‘Š")

        # è°ƒç”¨LLMç”ŸæˆæŠ¥å‘Š
        try:
            response = self.llm_client.call_smart_model(prompt, model_override=model_name, temperature=0.4)

            if not response or not response.get('success'):
                error_msg = f"LLMè°ƒç”¨å¤±è´¥: {response.get('error') if response else 'Unknown error'}"
                logger.warning(f"[{display_name}] {error_msg}")
                return {
                    'success': False,
                    'error': error_msg,
                    'model': model_name,
                    'model_display': display_name
                }

            llm_output = response.get('content', '')
        except Exception as e:
            error_msg = f"LLMè°ƒç”¨å¼‚å¸¸: {str(e)}"
            logger.error(f"[{display_name}] {error_msg}")
            return {
                'success': False,
                'error': error_msg,
                'model': model_name,
                'model_display': display_name
            }

        # ä¸ºLLMç”Ÿæˆçš„æŠ¥å‘Šæ·»åŠ æ ‡å‡†å¤´éƒ¨ä¿¡æ¯
        beijing_time = self._bj_time()
        header_info = [
            f"# ğŸ“Š X/Twitter æŠ€æœ¯æƒ…æŠ¥æ·±åº¦æŠ¥å‘Š - {display_name}",
            "",
            f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {beijing_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
            "",
            f"*æ•°æ®èŒƒå›´: {start_time.strftime('%Y-%m-%d %H:%M:%S')} - {end_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
            "",
            f"*åˆ†æåŠ¨æ€æ•°: {len(enriched_posts)} æ¡*",
            "",
            "---",
            ""
        ]

        # æ¸…ç†LLMè¾“å‡º
        cleaned_llm_output = self._clean_llm_output_for_notion(llm_output)

        sources_section = self._render_sources_section(sources)

        # æ„å»ºæŠ¥å‘Šå°¾éƒ¨
        footer_lines = ["", "---", ""]
        provider = response.get('provider')
        model = response.get('model')
        if provider:
            footer_lines.append(f"*åˆ†æå¼•æ“: {provider} ({model or 'unknown'})*")

        footer_lines.extend([
            "",
            f"ğŸ“Š **ç»Ÿè®¡æ‘˜è¦**: æœ¬æŠ¥å‘Šåˆ†æäº† {len(enriched_posts)} æ¡åŠ¨æ€",
            "",
            "*æœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ*"
        ])
        footer_section = "\n".join(footer_lines)

        report_content = "\n".join(header_info) + cleaned_llm_output + "\n\n" + sources_section + footer_section

        # åº”ç”¨æ¥æºé“¾æ¥å¢å¼º
        report_content = self._enhance_source_links(report_content, sources)

        title = f"XæŠ€æœ¯æƒ…æŠ¥æ·±åº¦æŠ¥å‘Š - {display_name} - {end_time.strftime('%Y-%m-%d %H:%M')}"

        # ä¿å­˜æŠ¥å‘Šåˆ°æ•°æ®åº“
        try:
            if self.db_manager.save_intelligence_report(
                'daily_deep',
                title,
                report_content,
                start_time,
                end_time
            ):
                logger.info(f"[{display_name}] æ·±åº¦æŠ¥å‘Šå·²æˆåŠŸä¿å­˜åˆ°æ•°æ®åº“")
            else:
                logger.warning(f"[{display_name}] æ·±åº¦æŠ¥å‘Šä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥")
        except Exception as e:
            logger.error(f"[{display_name}] ä¿å­˜æ·±åº¦æŠ¥å‘Šåˆ°æ•°æ®åº“æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")

        model_report = {
            'model': model_name,
            'model_display': display_name,
            'success': True,
            'report_title': title,
            'report_content': report_content,
            'provider': response.get('provider') if response else None,
            'items_analyzed': len(enriched_posts)
        }

        # å°è¯•æ¨é€åˆ°Notionï¼ˆä½¿ç”¨å±‚çº§ç»“æ„ï¼‰
        notion_push_info = None
        try:
            beijing_time = self._bj_time()
            time_str = beijing_time.strftime('%H:%M')
            notion_title = f"[{time_str}] [{display_name}] XæŠ€æœ¯æ·±åº¦æŠ¥å‘Š ({len(enriched_posts)}æ¡)"

            logger.info(f"å¼€å§‹æ¨é€æ·±åº¦æŠ¥å‘Šåˆ°Notion ({display_name}): {notion_title}")

            notion_result = x_intelligence_notion_client.create_report_page_in_hierarchy(
                report_title=notion_title,
                report_content=report_content,
                report_date=beijing_time,
                report_type='deep'
            )

            if notion_result.get('success'):
                logger.info(f"æ·±åº¦æŠ¥å‘ŠæˆåŠŸæ¨é€åˆ°Notion ({display_name}): {notion_result.get('page_url')}")
                notion_push_info = {
                    'success': True,
                    'page_url': notion_result.get('page_url'),
                    'path': notion_result.get('path')
                }
            else:
                error_msg = notion_result.get('error', 'æœªçŸ¥é”™è¯¯')
                logger.warning(f"æ¨é€æ·±åº¦æŠ¥å‘Šåˆ°Notionå¤±è´¥ ({display_name}): {error_msg}")
                notion_push_info = {
                    'success': False,
                    'error': error_msg
                }

        except Exception as e:
            logger.warning(f"æ¨é€æ·±åº¦æŠ¥å‘Šåˆ°Notionæ—¶å‡ºé”™ ({display_name}): {e}")
            notion_push_info = {
                'success': False,
                'error': str(e)
            }

        if notion_push_info:
            model_report['notion_push'] = notion_push_info

        return model_report

    async def run_dual_report_generation(self, hours: int = 24, limit: int = 300, candidate_multiplier: Optional[float] = None) -> Dict[str, Any]:
        """
        è¿è¡ŒåŒè½¨åˆ¶æŠ¥å‘Šç”Ÿæˆæµç¨‹
        å…ˆç”Ÿæˆæ‰€æœ‰æ—¥æŠ¥èµ„è®¯ï¼Œå†ç”Ÿæˆæ·±åº¦æŠ¥å‘Š

        Args:
            hours: æ—¶é—´èŒƒå›´ï¼ˆå°æ—¶ï¼‰
            limit: æœ€å¤§å¸–å­æ•°é‡
            candidate_multiplier: å€™é€‰æ± å€æ•°

        Returns:
            ç»¼åˆç»“æœ
        """
        logger.info(f"å¼€å§‹æ‰§è¡ŒåŒè½¨åˆ¶æŠ¥å‘Šç”Ÿæˆæµç¨‹: hours={hours}, limit={limit}, multiplier={candidate_multiplier}")

        dual_results = {
            'success': True,
            'light_reports': None,
            'deep_report': None
        }

        # ç¬¬ä¸€æ­¥: ç”Ÿæˆæ—¥æŠ¥èµ„è®¯
        logger.info("=== ç¬¬ä¸€æ­¥: ç”Ÿæˆæ—¥æŠ¥èµ„è®¯ ===")
        light_result = await self.generate_light_reports(hours, limit, candidate_multiplier)
        dual_results['light_reports'] = light_result

        if not light_result.get('success'):
            logger.warning("æ—¥æŠ¥èµ„è®¯ç”Ÿæˆå¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œæ·±åº¦æŠ¥å‘Š")
            dual_results['success'] = False
        else:
            logger.info(f"æ—¥æŠ¥èµ„è®¯ç”Ÿæˆå®Œæˆ: {len(light_result.get('model_reports', []))} ä¸ªæ¨¡å‹æˆåŠŸ")

        # ç¬¬äºŒæ­¥: ç”Ÿæˆæ·±åº¦æŠ¥å‘Š
        logger.info("=== ç¬¬äºŒæ­¥: ç”Ÿæˆæ·±åº¦æŠ¥å‘Š ===")
        deep_result = await self.generate_deep_report(hours, limit, candidate_multiplier)
        dual_results['deep_report'] = deep_result

        if not deep_result.get('success'):
            logger.error("æ·±åº¦æŠ¥å‘Šç”Ÿæˆå¤±è´¥")
            dual_results['success'] = False
        else:
            logger.info("æ·±åº¦æŠ¥å‘Šç”Ÿæˆå®Œæˆ")

        # æ±‡æ€»ç»Ÿè®¡
        total_items = 0
        if light_result.get('success'):
            total_items = light_result.get('items_analyzed', 0)
        elif deep_result.get('success'):
            total_items = deep_result.get('items_analyzed', 0)

        dual_results['items_analyzed'] = total_items
        dual_results['message'] = f"åŒè½¨åˆ¶æŠ¥å‘Šç”Ÿæˆ{'æˆåŠŸ' if dual_results['success'] else 'éƒ¨åˆ†å¤±è´¥'}"

        logger.info(f"åŒè½¨åˆ¶æŠ¥å‘Šç”Ÿæˆæµç¨‹å®Œæˆ: {dual_results['message']}")

        return dual_results

    def generate_kol_report(self, user_id: int, days: int = 30) -> Dict[str, Any]:
        """
        ç”ŸæˆKOLæ€æƒ³è½¨è¿¹æŠ¥å‘Š

        Args:
            user_id: ç”¨æˆ·ID
            days: åˆ†æå¤©æ•°

        Returns:
            ç”Ÿæˆç»“æœ
        """
        logger.info(f"å¼€å§‹ç”ŸæˆKOLæŠ¥å‘Šï¼Œç”¨æˆ·ID: {user_id}ï¼Œå¤©æ•°: {days}")

        try:
            # è·å–ç”¨æˆ·ä¿¡æ¯
            with self.db_manager.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT user_id FROM twitter_users WHERE id = %s", (user_id,))
                result = cursor.fetchone()
                if not result:
                    return {'success': False, 'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}
                user_handle = result[0]

            # è·å–ç”¨æˆ·æ¡£æ¡ˆ
            with self.db_manager.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute(
                    "SELECT profile_data FROM twitter_user_profiles WHERE user_table_id = %s",
                    (user_id,)
                )
                profile_result = cursor.fetchone()
                if not profile_result:
                    return {'success': False, 'error': 'ç”¨æˆ·æ¡£æ¡ˆä¸å­˜åœ¨'}

                user_profile_json = profile_result[0]

            # è·å–ç”¨æˆ·çš„å¯ŒåŒ–å¸–å­æ•°æ®
            enriched_posts = self.db_manager.get_user_enriched_posts(user_id, days)

            if not enriched_posts:
                return {'success': False, 'error': 'æ²¡æœ‰å¯ç”¨çš„å¸–å­æ•°æ®'}

            # æ ¼å¼åŒ–ç”¨æˆ·å¸–å­åˆé›†
            user_posts_collection = self._format_user_posts_for_kol_report(enriched_posts)

            # æ„å»ºKOLæŠ¥å‘Šæç¤ºè¯
            kol_prompt = self.get_kol_report_prompt(user_profile_json, user_posts_collection, user_handle)

            # è°ƒç”¨Smart LLMç”ŸæˆæŠ¥å‘Š
            response = self.llm_client.call_smart_model(kol_prompt, temperature=0.3)

            if not response['success']:
                return {'success': False, 'error': response.get('error')}

            report_content = response['content']
            report_title = f"@{user_handle} æ€æƒ³è½¨è¿¹æœˆåº¦æŠ¥å‘Š - {datetime.now().strftime('%Y-%m-%d')}"

            # ä¿å­˜æŠ¥å‘Š
            if self.db_manager.save_intelligence_report(
                'monthly_kol',
                report_title,
                report_content,
                related_user_id=user_id
            ):
                return {
                    'success': True,
                    'report_title': report_title,
                    'report_content': report_content,
                    'user_handle': user_handle
                }
            else:
                return {'success': False, 'error': 'æŠ¥å‘Šä¿å­˜å¤±è´¥', 'report_content': report_content}

        except Exception as e:
            logger.error(f"ç”ŸæˆKOLæŠ¥å‘Šæ—¶å‘ç”Ÿå¼‚å¸¸: {e}", exc_info=True)
            return {'success': False, 'error': str(e)}

    def _format_user_posts_for_kol_report(self, posts: List[Dict[str, Any]]) -> str:
        """ä¸ºKOLæŠ¥å‘Šæ ¼å¼åŒ–ç”¨æˆ·å¸–å­æ•°æ®"""
        formatted_posts = []
        for i, post in enumerate(posts, 1):
            published_at = post.get('published_at')
            time_str = published_at.strftime('%Y-%m-%d') if published_at else 'æœªçŸ¥æ—¥æœŸ'

            post_info = f"[T_{i}] [{time_str}] [{post.get('content_type', 'æœªçŸ¥ç±»å‹')}] [{post.get('post_tag', 'æ— æ ‡ç­¾')}] {post.get('post_content', '')}"
            formatted_posts.append(post_info)

        return '\n'.join(formatted_posts)

    def get_kol_report_prompt(self, user_profile_json: str, user_posts_collection: str, user_handle: str) -> str:
        """æ„å»ºKOLæŠ¥å‘Šæç¤ºè¯"""
        return f"""# Role: èµ„æ·±äººç‰©åˆ†æå¸ˆä¸ä¼ è®°ä½œå®¶

# Context:
ä½ æ­£åœ¨ä¸ºä¸€ä½é‡è¦çš„æŠ€æœ¯é¢†è¢–æ’°å†™ä¸€ä»½ç§å¯†çš„æœˆåº¦æ€æƒ³çºªè¦ã€‚ä½ çš„ä»»åŠ¡æ˜¯é€šè¯»ä»–/å¥¹æœ¬æœˆå‘å¸ƒçš„æ‰€æœ‰å¸–å­åŠå…¶æ•°å­—æ¡£æ¡ˆï¼Œæ¢³ç†å‡ºå…¶æ€æƒ³è„‰ç»œã€å…³æ³¨ç‚¹å˜åŒ–å’Œæ ¸å¿ƒæ´å¯Ÿã€‚

# Core Principles:
1.  **æ´å¯Ÿå…¶å˜ (Perceive the Change)**: ä½ çš„æ ¸å¿ƒæ˜¯å‘ç°"å˜åŒ–"ã€‚ä»–/å¥¹çš„å…³æ³¨ç‚¹ä»å“ªé‡Œè½¬ç§»åˆ°äº†å“ªé‡Œï¼Ÿå¯¹æŸä¸ªé—®é¢˜çš„çœ‹æ³•æ˜¯å¦å‘ç”Ÿäº†æ”¹å˜ï¼Ÿ
2.  **æŠ“ä½ç²¾é«“ (Capture the Essence)**: ä¸è¦æµæ°´è´¦ã€‚ä½ éœ€è¦æç‚¼å‡ºä»–/å¥¹æœ¬æœˆæœ€é—ªå…‰çš„ã€æœ€å…·ä»£è¡¨æ€§çš„è§‚ç‚¹å’Œåˆ†äº«ã€‚
3.  **å®¢è§‚ä¸­ç«‹ (Stay Objective)**: ä½ çš„åˆ†æåº”åŸºäºåŸæ–‡ï¼Œé¿å…è¿‡åº¦è§£è¯»å’Œä¸»è§‚è‡†æ–­ã€‚

# Input Data:
1.  **ç”¨æˆ·æ•°å­—æ¡£æ¡ˆ**:
    '''
    {user_profile_json}
    '''
2.  **æœ¬æœˆè¨€è®ºåˆé›†**:
    '''
    {user_posts_collection}
    '''

# Your Task:
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ç»“æ„ï¼Œç”Ÿæˆä¸€ä»½å…³äº @{user_handle} çš„æœˆåº¦æ€æƒ³è½¨è¿¹æŠ¥å‘Šã€‚

## 1. æœ¬æœˆæ ¸å¿ƒå…³æ³¨ç‚¹
*   **é¢†åŸŸA**: [æè¿°...]
*   **é¢†åŸŸB**: [æè¿°...]

---

## 2. å…³é”®è§‚ç‚¹ä¸ç«‹åœºæ¼”å˜
### 2.1 æœ¬æœˆé‡‘å¥
> [å¼•ç”¨çš„"é‡‘å¥"]
*   **è§£è¯»**: [ä½ å¯¹æ­¤å¥è¯çš„è§£è¯»...]
### 2.2 ç«‹åœºåˆ†æ (å¯é€‰)
*   å…³äº"[è¯é¢˜]"çš„è§‚ç‚¹ï¼Œä»[æ—§è§‚ç‚¹]æ¼”å˜ä¸º[æ–°è§‚ç‚¹]ï¼Œä¸»è¦ä½“ç°åœ¨...

---

## 3. é«˜ä»·å€¼åˆ†äº«ä¸ç½‘ç»œäº’åŠ¨
### 3.1 é«˜ä»·å€¼åˆ†äº«
*   **[é¡¹ç›®/æ–‡ç« A]**: [ä»·å€¼è¯´æ˜] [Source: T_n]
*   **[é¡¹ç›®/æ–‡ç« B]**: [ä»·å€¼è¯´æ˜] [Source: T_m]
### 3.2 æ ¸å¿ƒäº’åŠ¨
*   æœ¬æœˆä¸ `@user_handle` çš„å…³äº [è¯é¢˜] çš„è®¨è®ºå€¼å¾—å…³æ³¨ï¼Œæ­ç¤ºäº†...

---

## 4. æ€æƒ³è½¨è¿¹æ€»ç»“
[æ€»ç»“å†…å®¹...]"""


def run_daily_intelligence_report(hours: int = 24, limit: int = 300, candidate_multiplier: Optional[float] = None) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•°ï¼šè¿è¡Œæ—¥åº¦æƒ…æŠ¥æŠ¥å‘Šç”Ÿæˆï¼ˆä¿ç•™å…¼å®¹æ€§ï¼Œä½¿ç”¨åŸæœ‰çš„å¤šæ¨¡å‹å¹¶è¡Œæ–¹å¼ï¼‰

    Args:
        hours: æ—¶é—´èŒƒå›´ï¼ˆå°æ—¶ï¼‰
        limit: æœ€å¤§å¸–å­æ•°é‡
        candidate_multiplier: å€™é€‰æ± å€æ•°

    Returns:
        ç”Ÿæˆç»“æœ
    """
    generator = IntelligenceReportGenerator()
    return asyncio.run(generator.generate_intelligence_report(hours, limit, candidate_multiplier))


def run_light_reports(hours: int = 24, limit: int = 300, candidate_multiplier: Optional[float] = None) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•°ï¼šè¿è¡Œæ—¥æŠ¥èµ„è®¯ç”Ÿæˆ

    Args:
        hours: æ—¶é—´èŒƒå›´ï¼ˆå°æ—¶ï¼‰
        limit: æœ€å¤§å¸–å­æ•°é‡
        candidate_multiplier: å€™é€‰æ± å€æ•°

    Returns:
        ç”Ÿæˆç»“æœ
    """
    generator = IntelligenceReportGenerator()
    return asyncio.run(generator.generate_light_reports(hours, limit, candidate_multiplier))


def run_deep_report(hours: int = 24, limit: int = 300, candidate_multiplier: Optional[float] = None) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•°ï¼šè¿è¡Œæ·±åº¦æŠ¥å‘Šç”Ÿæˆ

    Args:
        hours: æ—¶é—´èŒƒå›´ï¼ˆå°æ—¶ï¼‰
        limit: æœ€å¤§å¸–å­æ•°é‡
        candidate_multiplier: å€™é€‰æ± å€æ•°

    Returns:
        ç”Ÿæˆç»“æœ
    """
    generator = IntelligenceReportGenerator()
    return asyncio.run(generator.generate_deep_report(hours, limit, candidate_multiplier))


def run_dual_reports(hours: int = 24, limit: int = 300, candidate_multiplier: Optional[float] = None) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•°ï¼šè¿è¡ŒåŒè½¨åˆ¶æŠ¥å‘Šç”Ÿæˆï¼ˆå…ˆæ—¥æŠ¥èµ„è®¯ï¼Œåæ·±åº¦æŠ¥å‘Šï¼‰

    Args:
        hours: æ—¶é—´èŒƒå›´ï¼ˆå°æ—¶ï¼‰
        limit: æœ€å¤§å¸–å­æ•°é‡
        candidate_multiplier: å€™é€‰æ± å€æ•°

    Returns:
        ç”Ÿæˆç»“æœ
    """
    generator = IntelligenceReportGenerator()
    return asyncio.run(generator.run_dual_report_generation(hours, limit, candidate_multiplier))


def run_kol_report(user_id: int, days: int = 30) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•°ï¼šè¿è¡ŒKOLæŠ¥å‘Šç”Ÿæˆ

    Args:
        user_id: ç”¨æˆ·ID
        days: åˆ†æå¤©æ•°

    Returns:
        ç”Ÿæˆç»“æœ
    """
    generator = IntelligenceReportGenerator()
    return generator.generate_kol_report(user_id, days)
