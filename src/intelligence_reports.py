"""
æƒ…æŠ¥æŠ¥å‘Šç”Ÿæˆå™¨ (Intelligence Report Generator)
åŸºäºå¯ŒåŒ–åçš„å¸–å­æ•°æ®ï¼Œç”Ÿæˆé«˜è´¨é‡çš„æƒ…æŠ¥åˆ†ææŠ¥å‘Š
æ”¯æŒå¤šæ¨¡å‹å¹¶è¡Œç”Ÿæˆå’Œ Notion æ¨é€
å‚è€ƒ info-collector-jk é¡¹ç›®çš„é«˜çº§æ¶æ„
"""
import logging
import json
import asyncio
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime, timezone, timedelta
import re

from .database import DatabaseManager
from .llm_client import get_llm_client
from .config import config
from .notion_client import x_intelligence_notion_client

logger = logging.getLogger(__name__)


class IntelligenceReportGenerator:
    """æƒ…æŠ¥æŠ¥å‘Šç”Ÿæˆå™¨ï¼Œæ”¯æŒå¤šæ¨¡å‹å¹¶è¡Œç”Ÿæˆå’Œ Notion æ¨é€"""

    def __init__(self, db_manager: Optional[DatabaseManager] = None):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨"""
        if db_manager is not None:
            self.db_manager = db_manager
        else:
            self.db_manager = DatabaseManager(config)

        self.llm_client = get_llm_client()
        if not self.llm_client:
            raise RuntimeError("LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆæƒ…æŠ¥æŠ¥å‘Š")

        # è·å–LLMé…ç½®
        llm_config = config.get_llm_config()
        self.max_content_length = int(llm_config.get('max_content_length', 380000))
        self.max_llm_concurrency = 3  # å¹¶å‘æ¨¡å‹æ•°é‡é™åˆ¶

        logger.info("æƒ…æŠ¥æŠ¥å‘Šç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")

    def _log_task_start(self, task_type: str, **kwargs) -> None:
        """ç»Ÿä¸€çš„ä»»åŠ¡å¼€å§‹æ—¥å¿—è®°å½•"""
        details = ", ".join([f"{k}={v}" for k, v in kwargs.items()])
        logger.info(f"å¼€å§‹æ‰§è¡Œ {task_type} ä»»åŠ¡: {details}")

    def _log_task_complete(self, task_type: str, success_count: int, failure_count: int, **kwargs) -> None:
        """ç»Ÿä¸€çš„ä»»åŠ¡å®Œæˆæ—¥å¿—è®°å½•"""
        status = "æˆåŠŸ" if failure_count == 0 else f"éƒ¨åˆ†æˆåŠŸ"
        details = ", ".join([f"{k}={v}" for k, v in kwargs.items()])
        logger.info(f"{task_type} ä»»åŠ¡å®Œæˆ ({status}): æˆåŠŸ {success_count} ä¸ªï¼Œå¤±è´¥ {failure_count} ä¸ªã€‚{details}")

    def _handle_task_exception(self, task_type: str, model_name: str, display_name: str, exception: Exception) -> Dict[str, Any]:
        """ç»Ÿä¸€çš„ä»»åŠ¡å¼‚å¸¸å¤„ç†"""
        error_msg = str(exception)
        logger.warning(f"{task_type} ä»»åŠ¡å¼‚å¸¸ - æ¨¡å‹ {model_name} ({display_name}): {error_msg}")
        return {
            'model': model_name,
            'model_display': display_name,
            'success': False,
            'error': error_msg,
            'error_type': type(exception).__name__
        }

    def _create_error_response(self, error_msg: str, **additional_fields) -> Dict[str, Any]:
        """åˆ›å»ºæ ‡å‡†åŒ–çš„é”™è¯¯å“åº”"""
        response = {
            'success': False,
            'error': error_msg,
            'items_analyzed': 0
        }
        response.update(additional_fields)
        return response

    def _bj_time(self) -> datetime:
        """è·å–åŒ—äº¬æ—¶é—´"""
        return datetime.now(timezone.utc) + timedelta(hours=8)

    def _get_report_models(self) -> List[str]:
        """è·å–ç”¨äºç”ŸæˆæŠ¥å‘Šçš„æ¨¡å‹åˆ—è¡¨"""
        if not self.llm_client:
            return []

        models: List[str] = []

        # å…ˆå°è¯•ä» llm_client çš„ report_models å±æ€§è·å–
        raw_models = getattr(self.llm_client, 'report_models', None) or []
        for model_name in raw_models:
            if model_name and model_name not in models:
                models.append(model_name)

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ¨¡å‹åˆ—è¡¨ï¼Œä½¿ç”¨åŸºç¡€å’Œä¼˜å…ˆæ¨¡å‹
        if not models:
            base_model = getattr(self.llm_client, 'smart_model', None)
            priority_model = getattr(self.llm_client, 'priority_model', None)

            if base_model:
                models.append(base_model)
            if priority_model and priority_model not in models:
                models.insert(0, priority_model)

        return models

    def _get_model_display_name(self, model_name: str) -> str:
        """æ ¹æ®æ¨¡å‹åç§°ç”Ÿæˆç”¨äºå±•ç¤ºçš„å‹å¥½åç§°"""
        if not model_name:
            return 'LLM'

        lower_name = model_name.lower()
        if 'gemini' in lower_name:
            return 'Gemini'
        if 'glm' in lower_name and '4.5' in lower_name:
            return 'GLM4.5'
        if 'glm' in lower_name:
            return 'GLM'
        if 'gpt' in lower_name:
            return 'GPT'
        if 'claude' in lower_name:
            return 'Claude'

        return model_name

    def format_enriched_posts_for_smart_llm(self, enriched_posts: List[Dict[str, Any]]) -> Tuple[str, List[Dict[str, Any]]]:
        """
        ä¸ºSmart LLMæ ¼å¼åŒ–å¯ŒåŒ–åçš„å¸–å­æ•°æ®
        å……åˆ†åˆ©ç”¨ PostInsightsAnalyzer çš„è¾“å‡ºç»“æœ

        Args:
            enriched_posts: å¯ŒåŒ–åçš„å¸–å­æ•°æ®åˆ—è¡¨

        Returns:
            (æ ¼å¼åŒ–åçš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸², æºæ˜ å°„åˆ—è¡¨)
        """
        context_parts = []
        sources = []
        total_chars = 0

        for i, post_data in enumerate(enriched_posts, 1):
            sid = f"T{i}"

            # åŸºç¡€ä¿¡æ¯
            user_id = post_data.get('user_id', 'unknown')
            post_url = post_data.get('post_url', 'æœªçŸ¥')
            published_at = post_data.get('published_at')
            pub_str = published_at.strftime('%Y-%m-%d %H:%M') if published_at else 'æœªçŸ¥æ—¶é—´'

            # ä» PostInsightsAnalyzer è·å–çš„å¯ŒåŒ–æ•°æ®
            llm_summary = post_data.get('llm_summary', 'æ— æ‘˜è¦')
            post_tag = post_data.get('post_tag', 'æ— æ ‡ç­¾')
            content_type = post_data.get('content_type', 'æœªçŸ¥ç±»å‹')

            # æåŠå®ä½“ä¿¡æ¯
            mentioned_entities = post_data.get('mentioned_entities')
            entities_str = "æ— "
            if mentioned_entities and mentioned_entities != 'null':
                try:
                    if isinstance(mentioned_entities, str):
                        entities_list = json.loads(mentioned_entities)
                    else:
                        entities_list = mentioned_entities
                    entities_str = ", ".join([
                        f"{entity.get('entity_name')} ({entity.get('entity_type')})"
                        for entity in entities_list
                        if entity and entity.get('entity_name')
                    ])
                    if not entities_str:
                        entities_str = "æ— "
                except (json.JSONDecodeError, TypeError):
                    entities_str = "æ— "

            # æ·±åº¦æ´å¯Ÿ - è¿™æ˜¯æœ€é‡è¦çš„éƒ¨åˆ†
            deep_interpretation = (post_data.get('deep_interpretation') or '').strip()
            if not deep_interpretation:
                deep_interpretation = "æ— æ·±åº¦æ´å¯Ÿ"
            elif len(deep_interpretation) > 2000:
                deep_interpretation = deep_interpretation[:2000] + "..."

            # å›¾ç‰‡æè¿°ï¼ˆå¦‚æœæœ‰ï¼‰
            image_description = post_data.get('image_description', '')
            image_section = ""
            if image_description:
                image_section = f"- å›¾ç‰‡æè¿°: {self._truncate(image_description, 300)}\n"

            # åŸå§‹å†…å®¹èŠ‚é€‰
            original_content = post_data.get('post_content', '')
            content_excerpt = self._truncate(original_content, 500)

            # æ„å»ºå•ä¸ªå¸–å­çš„ä¸Šä¸‹æ–‡å—
            block = f"""
[Source: {sid} | User: @{user_id}]
- å‘å¸ƒæ—¶é—´: {pub_str}
- å†…å®¹ç±»å‹: {content_type}
- å†…å®¹æ ‡ç­¾: {post_tag}
- æåŠå®ä½“: {entities_str}
- LLMæ‘˜è¦: {llm_summary}
{image_section}- æ·±åº¦æ´å¯Ÿ:
'''
{deep_interpretation}
'''
- å¸–å­é“¾æ¥: {post_url}
- åŸå§‹å†…å®¹èŠ‚é€‰:
'''
{content_excerpt}
'''
"""

            # æ£€æŸ¥é•¿åº¦é™åˆ¶
            if total_chars + len(block) > self.max_content_length:
                logger.info(f"è¾¾åˆ°æœ€å¤§å†…å®¹é™åˆ¶({self.max_content_length}),æˆªæ–­å¸–å­åˆ—è¡¨äºç¬¬ {i-1} æ¡")
                break

            context_parts.append(block)
            total_chars += len(block)

            # æ·»åŠ åˆ°æºæ˜ å°„
            sources.append({
                'sid': sid,
                'title': self._truncate(llm_summary, 100),
                'link': post_url,
                'nickname': user_id,
                'excerpt': self._truncate(content_excerpt, 120)
            })

        return "\n---\n".join(context_parts), sources

    def _truncate(self, text: str, max_len: int) -> str:
        """æˆªæ–­æ–‡æœ¬ï¼Œä¿æŒå¯è¯»æ€§"""
        if not text:
            return ""
        if len(text) <= max_len:
            return text
        t = text[:max_len]
        # å°è¯•åœ¨å¥å°¾æˆªæ–­
        for d in ['ã€‚', '!', '?', '.', '!', '?', '\n']:
            pos = t.rfind(d)
            if pos > max_len * 0.7:
                return t[:pos + 1] + "\n..."
        return t + "\n..."

    def get_intelligence_report_prompt(self, formatted_context: str, time_range: str) -> str:
        """
        æ„å»ºæƒ…æŠ¥åˆ†ææŠ¥å‘Šçš„æç¤ºè¯ã€‚
        æç¤ºè¯å†…å®¹ç›´æ¥å†…è”åœ¨æ­¤å‡½æ•°ä¸­ï¼Œä»¥å‡å°‘å¤–éƒ¨æ–‡ä»¶ä¾èµ–ã€‚
        """
        # å®šä¹‰ç²¾ç¡®çš„æ•°æ®æ ¼å¼æè¿°ï¼Œä»¥åŒ¹é… format_enriched_posts_for_smart_llm çš„è¾“å‡º
        # è¿™éƒ¨åˆ†å†…å®¹æ—¨åœ¨å‘ŠçŸ¥LLMå…¶æ¥æ”¶åˆ°çš„`formatted_context`ä¸­æ¯ä¸ªå¸–å­çš„è¯¦ç»†ç»“æ„
        accurate_data_format_description = """# Input Data Format:
ä½ å°†æ”¶åˆ°ä¸€ç³»åˆ—ç»è¿‡é¢„å¤„ç†çš„ã€ä¿¡æ¯ä¸°å¯Œçš„å¸–å­æ‘˜è¦ï¼Œç»“æ„å¦‚ä¸‹ã€‚è¯·é‡ç‚¹åˆ©ç”¨`æ·±åº¦æ´å¯Ÿ`éƒ¨åˆ†è¿›è¡Œåˆ†æã€‚
`[Source: T_id | User: user_handle]`
- å‘å¸ƒæ—¶é—´: {å‘å¸ƒæ—¶é—´}
- å†…å®¹ç±»å‹: {LLMè¯†åˆ«çš„å†…å®¹ç±»å‹}
- å†…å®¹æ ‡ç­¾: {LLMç”Ÿæˆçš„å†…å®¹æ ‡ç­¾}
- æåŠå®ä½“: {LLMæå–çš„å®ä½“}
- LLMæ‘˜è¦: {LLMç”Ÿæˆçš„å•å¥æ‘˜è¦}
- æ·±åº¦æ´å¯Ÿ:
'''
{LLMç”Ÿæˆçš„æ·±åº¦è§£è¯»ï¼Œè¿™æ˜¯ä½ åˆ†æçš„æ ¸å¿ƒä¾æ®}
'''
- å¸–å­é“¾æ¥: {å¸–å­åŸå§‹é“¾æ¥}
- åŸå§‹å†…å®¹èŠ‚é€‰:
'''
{å¸–å­åŸå§‹å†…å®¹çš„èŠ‚é€‰}
'''"""

        # æ ¸å¿ƒæç¤ºè¯æ¨¡æ¿
        prompt_template = f"""# Role: ä¸–ç•Œçº§æŠ€æœ¯ä¸æŠ•èµ„æƒ…æŠ¥åˆ†æå¸ˆå…¼ã€Šç»æµå­¦äººã€‹èµ„æ·±ç¼–è¾‘

# Context:
ä½ æ­£åœ¨ä¸ºä¸€ä»½é¡¶çº§å†…å‚æ’°å†™æŠ¥å‘Šï¼Œè¯»è€…æ˜¯å…¨çƒå¤´éƒ¨çš„æŠ€æœ¯ä¸“å®¶ã€åˆ›ä¸šè€…å’Œé£é™©æŠ•èµ„äººã€‚ä»–ä»¬æ—¶é—´å®è´µï¼Œæåº¦å…³æ³¨"ä¿¡å·"ï¼ŒåŒæ¶"å™ªéŸ³"ã€‚ä½ æ”¶åˆ°çš„åŸå§‹ææ–™æ˜¯{time_range}å†…ï¼Œç”±æˆ‘ä»¬ç²¾å¿ƒç­›é€‰çš„çº¦300ä½å…¨çƒæŠ€æœ¯æ€æƒ³é¢†è¢–åœ¨X/Twitterä¸Šå‘å¸ƒçš„å¸–å­ã€‚è¿™äº›ææ–™å·²ç»è¿‡ç»Ÿä¸€çš„æ´å¯Ÿå¼•æ“å¤„ç†ï¼ŒåŒ…å«ç»“æ„åŒ–è¦ç‚¹ä¸æ·±åº¦è§£è¯»ã€‚

# Core Principles:
1.  **æ·±åº¦ä¸ä»·å€¼ä¼˜å…ˆ (Depth & Value First)**: ä½ çš„æ ¸å¿ƒç›®æ ‡æ˜¯æŒ–æ˜å‡ºå¯¹ä»ä¸šè€…æœ‰ç›´æ¥ä»·å€¼çš„ä¿¡æ¯ã€‚åœ¨æ’°å†™æ¯ä¸ªéƒ¨åˆ†æ—¶ï¼Œéƒ½åº”è¿½æ±‚å†…å®¹çš„**æ·±åº¦å’Œå®Œæ•´æ€§**ï¼Œ**é¿å…è¿‡äºç®€çŸ­çš„æ¦‚æ‹¬**ã€‚
2.  **æ·±åº¦åˆæˆ (Deep Synthesis)**: ä¸è¦ç®€å•ç½—åˆ—ã€‚ä½ éœ€è¦å°†ä¸åŒæ¥æºçš„ä¿¡æ¯ç‚¹è¿æ¥èµ·æ¥ï¼Œæ„å»ºæˆæœ‰æ„ä¹‰çš„å™äº‹ï¼ˆNarrativeï¼‰ã€‚
3.  **æ³¨å…¥æ´è§ (Inject Insight)**: ä½ ä¸æ˜¯ä¸€ä¸ªæ€»ç»“è€…ï¼Œè€Œæ˜¯ä¸€ä¸ªåˆ†æå¸ˆã€‚åœ¨é™ˆè¿°äº‹å®å’Œè§‚ç‚¹çš„åŸºç¡€ä¸Šï¼Œ**å¿…é¡»**åŠ å…¥ä½ è‡ªå·±çš„ã€åŸºäºä¸Šä¸‹æ–‡çš„ã€æœ‰æ·±åº¦çš„åˆ†æå’Œè¯„è®ºã€‚
4.  **ç»å¯¹å¯è¿½æº¯ (Absolute Traceability)**: ä½ çš„æ¯ä¸€æ¡æ´å¯Ÿã€åˆ¤æ–­å’Œå»ºè®®ï¼Œéƒ½å¿…é¡»åœ¨å¥æœ«ä½¿ç”¨ `[Source: T_n]` æˆ– `[Sources: T_n, T_m]` çš„æ ¼å¼æ˜ç¡®æ ‡æ³¨ä¿¡æ¯æ¥æºã€‚è¿™æ˜¯ç¡¬æ€§è¦æ±‚,ç»å¯¹ä¸èƒ½é—æ¼ã€‚

{accurate_data_format_description}

# Your Task:
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹äº”ä¸ªå±‚æ¬¡çš„åˆ†ææ¡†æ¶ï¼Œç”Ÿæˆä¸€ä»½**å†…å®¹ä¸°å¯Œè¯¦å®ã€ä¿¡æ¯å¯†åº¦æé«˜ã€æ´å¯Ÿæ·±åˆ»**çš„å®Œæ•´Markdownæƒ…æŠ¥æŠ¥å‘Šã€‚

**ç¬¬ä¸€å±‚æ¬¡ï¼šåŠ¨æ€ä¸çƒ­ç‚¹æ¦‚è§ˆ (Dynamics & Hotspot Overview)**
*   **1.1 åŠ¨æ€æ‘˜è¦**: å†™ä¸€ä¸ª300å­—å·¦å³çš„"æ‰§è¡Œæ‘˜è¦"ï¼Œæ€»ç»“å‘¨æœŸå†…æœ€é‡è¦çš„åŠ¨æ€å’Œæœ€å…³é”®çš„ä¿¡å·ã€‚
*   **1.2 æ ¸å¿ƒè¯é¢˜**: è¯†åˆ«å‡ºæœ¬å‘¨æœŸå†…æ‰€æœ‰å€¼å¾—å…³æ³¨çš„æ ¸å¿ƒè¯é¢˜ã€‚å¯¹æ¯ä¸ªè¯é¢˜ï¼Œ**è¯¦ç»†é˜è¿°**å…¶æ ¸å¿ƒè®®é¢˜ï¼Œå¹¶**å°½å¯èƒ½å…¨é¢åœ°**åˆ—å‡ºæœ€å…·ä»£è¡¨æ€§çš„è§‚ç‚¹å’Œè®¨è®ºæ–¹å‘ã€‚

**ç¬¬äºŒå±‚æ¬¡ï¼šè§‚ç‚¹å¯¹æ’åœ†æ¡Œ (Perspectives Collision Round-table)**
*   ä»»åŠ¡ï¼šå›´ç»•æœ¬å‘¨æœŸå†…3ä¸ªæœ€å…·äº‰è®®æ€§æˆ–å¤šé¢æ€§çš„è¯é¢˜ï¼Œåˆ†åˆ«ç»„ç»‡è™šæ‹Ÿåœ†æ¡Œè®¨è®ºã€‚
*   è¦æ±‚ï¼ˆæ¯åœºï¼‰ï¼š
    1.  **è®¾å®šè®®é¢˜**: æ˜ç¡®æœ¬åœºåœ†æ¡Œçš„æ ¸å¿ƒè®®é¢˜ã€‚
    2.  **é‚€è¯·å˜‰å®¾**: ä»æ•°æ®ä¸­æŒ‘é€‰æŒæœ‰ä¸åŒï¼ˆç”šè‡³å¯¹ç«‹ï¼‰è§‚ç‚¹çš„ç”¨æˆ·ä½œä¸º"è™šæ‹Ÿå˜‰å®¾"ã€‚
    3.  **å‘ˆç°è§‚ç‚¹**: æ¸…æ™°åœ°å±•ç¤ºæ¯ä½å˜‰å®¾çš„æ ¸å¿ƒè®ºç‚¹ï¼Œå¹¶ç›´æ¥å¼•ç”¨å…¶åŸæ–‡ç²¾åã€‚
    4.  **åˆ†æå¸ˆç‚¹è¯„ (å…³é”®ï¼)**: åœ¨æ‰€æœ‰è§‚ç‚¹é™ˆè¿°å®Œæ¯•åï¼Œ**åŠ å…¥ä½ è‡ªå·±çš„ã€ç¯‡å¹…å……è¶³çš„åˆ†æå¸ˆç‚¹è¯„**ã€‚ç‚¹è¯„å†…å®¹åº”åŒ…æ‹¬ä½†ä¸é™äºï¼šæŒ‡å‡ºå„æ–¹è§‚ç‚¹çš„ç›²åŒºã€ç‚¹æ˜äº‰è®®çš„æœ¬è´¨ã€é¢„æµ‹è¯¥è®®é¢˜çš„æœªæ¥èµ°å‘ã€æˆ–è€…æå‡ºä¸€ä¸ªæ›´é«˜ç»´åº¦çš„ç»¼åˆæ€§çœ‹æ³•ã€‚
    5.  **å¤‡é€‰æ–¹æ¡ˆ**: å¦‚æœæœ¬å‘¨æœŸå†…æ²¡æœ‰æ˜æ˜¾å¯¹ç«‹çš„è§‚ç‚¹ï¼Œè¯·é€‰æ‹©ä¸€ä¸ªæ ¸å¿ƒè¯é¢˜ï¼Œ**æ·±å…¥å‰–æ**å…¶ä¸åŒè§’åº¦ï¼ˆå¦‚å¼€å‘è€…ã€äº§å“ç»ç†ã€ç”¨æˆ·ï¼‰çš„è®ºè¿°ï¼Œæˆ–å°†å…¶æ”¹ä¸ºå¯¹ä¸€ä¸ªå…³é”®äººç‰©æ ¸å¿ƒè§‚ç‚¹çš„æ·±åº¦å‰–æã€‚

**ç¬¬ä¸‰å±‚æ¬¡ï¼šè¶‹åŠ¿ä¸å™äº‹æ·±åº¦åˆ†æ (Trend & Narrative Analysis)**
*   **3.1 æ–°å…´è¶‹åŠ¿/ä¿¡å·**: è¯†åˆ«æ‰€æœ‰è®¨è®ºåº¦å¿«é€Ÿä¸Šå‡çš„"æ–°å…´è¶‹åŠ¿"æˆ–"å¾®å¼±ä¿¡å·"ã€‚**è¯¦ç»†æè¿°**å®ƒæ˜¯ä»€ä¹ˆï¼Œä¸ºä»€ä¹ˆå®ƒç°åœ¨å‡ºç°ï¼Œä»¥åŠå®ƒå¯èƒ½å¯¹è¡Œä¸šäº§ç”Ÿä»€ä¹ˆå½±å“ã€‚**ä¸è¦å±€é™äºå°‘æ•°å‡ ç‚¹**ã€‚
*   **3.2 å®å¤§å™äº‹**: å¯»æ‰¾ä¸åŒè¯é¢˜ä¹‹é—´çš„å†…åœ¨è”ç³»ï¼Œæ„å»ºä¸€ä¸ªæˆ–å¤šä¸ªå®å¤§å™äº‹ã€‚**è¯¦ç»†å±•å¼€**è¿™ä¸ªå™äº‹ï¼Œä¾‹å¦‚ï¼Œå°†"æ–°AIæ¨¡å‹çš„å‘å¸ƒ"ã€"å¼€æºç¤¾åŒºçš„è®¨è®º"å’Œ"ä¸‹æ¸¸åº”ç”¨çš„æ¢ç´¢"è”ç³»èµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªå…³äº"XXXæŠ€æœ¯ä»ç†è®ºåˆ°å®è·µçš„æ¼”è¿›è·¯å¾„"çš„å®Œæ•´å™äº‹ã€‚

**ç¬¬å››å±‚æ¬¡ï¼šç²¾é€‰èµ„æºåº“ (Curated Resource Library)**
*   ä»»åŠ¡ï¼šä»æœ¬å‘¨æœŸæ‰€æœ‰åˆ†äº«çš„é“¾æ¥ä¸­ï¼Œç²¾é€‰å‡º**æ‰€æœ‰å…·å¤‡é«˜ä»·å€¼**çš„èµ„æºã€‚
*   è¦æ±‚ï¼š
    *   **4.1 æ•™ç¨‹ä¸æŒ‡å—**: æŒ‘é€‰å‡ºæ‰€æœ‰æœ‰ä»·å€¼çš„æ•™ç¨‹ã€æŒ‡å—æˆ–æ·±åº¦å­¦ä¹ ç¬”è®°ã€‚
    *   **4.2 å·¥å…·ä¸é¡¹ç›®**: æŒ‘é€‰å‡ºæ‰€æœ‰å€¼å¾—å…³æ³¨çš„æ–°å·¥å…·æˆ–å¼€æºé¡¹ç›®ã€‚
    *   å¯¹æ¯ä¸ªå…¥é€‰çš„èµ„æºï¼Œ**ç”¨ä¸€æ®µè¯è¯¦ç»†è¯´æ˜**å…¶æ ¸å¿ƒä»·å€¼å’Œæ¨èç†ç”±ï¼Œè€Œä¸ä»…ä»…æ˜¯ä¸€å¥è¯æ¦‚æ‹¬ã€‚

**ç¬¬äº”å±‚æ¬¡ï¼šè§’è‰²åŒ–è¡ŒåŠ¨å»ºè®® (Role-Based Actionable Recommendations)**
*   ä»»åŠ¡ï¼šå°†æ‰€æœ‰åˆ†æè½¬åŒ–ä¸ºå¯¹ç‰¹å®šè§’è‰²çš„ã€**ä¸°å¯Œä¸”å…·ä½“**çš„ã€å¯ç«‹å³æ‰§è¡Œçš„å»ºè®®ã€‚
*   è¦æ±‚ï¼šå»ºè®®å¿…é¡»å…·ä½“ã€æ–°é¢–ä¸”å…·æœ‰å‰ç»æ€§ï¼Œå¹¶é˜è¿°å…¶èƒŒåçš„é€»è¾‘ã€‚
    *   **ç»™å¼€å‘è€…çš„å»ºè®®**: [ä¾‹å¦‚ï¼šå»ºè®®ç«‹å³ç ”ç©¶ `XXX` æ¡†æ¶ï¼Œå› ä¸ºå®ƒåœ¨è§£å†³ `YYY` é—®é¢˜ä¸Šè¡¨ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚ç¤¾åŒºè®¨è®ºè¡¨æ˜...] [Source: T_n]
    *   **ç»™äº§å“ç»ç†/åˆ›ä¸šè€…çš„å»ºè®®**: [ä¾‹å¦‚ï¼šç¤¾åŒºå¯¹ `ZZZ` åœºæ™¯çš„éœ€æ±‚åå¤å‡ºç°ï¼Œä½†ç°æœ‰è§£å†³æ–¹æ¡ˆå‡æœ‰ç¼ºé™·ï¼Œè¿™å¯èƒ½æ˜¯ä¸€ä¸ªè¢«å¿½è§†çš„è“æµ·å¸‚åœºã€‚å…·ä½“è¡¨ç°ä¸º...] [Source: T_m]
    *   **ç»™æŠ•èµ„è€…çš„å»ºè®®**: [ä¾‹å¦‚ï¼š`AAA` é¢†åŸŸçš„è®¨è®ºçƒ­åº¦ä¸æŠ€æœ¯æˆç†Ÿåº¦å‡ºç°"å…±æŒ¯"ï¼Œå¯èƒ½é¢„ç¤ºç€å•†ä¸šåŒ–æ‹ç‚¹å³å°†åˆ°æ¥ã€‚å…³é”®ä¿¡å·åŒ…æ‹¬...] [Source: T_k]
    *   ...(è¯·ä¸ºæ¯ä¸ªè§’è‰²æä¾›**å°½å¯èƒ½å¤š**çš„æœ‰ä»·å€¼å»ºè®®)

# Output Format (Strictly follow this Markdown structure):

## ä¸€ã€åŠ¨æ€ä¸çƒ­ç‚¹æ¦‚è§ˆ
### 1.1 åŠ¨æ€æ‘˜è¦
[æ‰§è¡Œæ‘˜è¦å†…å®¹]
### 1.2 æ ¸å¿ƒè¯é¢˜
*   **è¯é¢˜A**: [è¯¦ç»†é˜è¿°]
    *   è§‚ç‚¹1: [å†…å®¹] [Source: T_n]
    *   è§‚ç‚¹2: [å†…å®¹] [Source: T_m]
    *   ... (æ›´å¤šè§‚ç‚¹)
*   **è¯é¢˜B**: ...
*   ... (æ›´å¤šè¯é¢˜)

---

## äºŒã€è§‚ç‚¹å¯¹æ’åœ†æ¡Œï¼š[è®®é¢˜åç§°]
### å˜‰å®¾è§‚ç‚¹
*   **æ­£æ–¹ä»£è¡¨ (`@user_handle_1`)**: [è§‚ç‚¹é™ˆè¿°] [Source: T_a]
*   **åæ–¹ä»£è¡¨ (`@user_handle_2`)**: [è§‚ç‚¹é™ˆè¿°] [Source: T_b]
*   **ä¸­ç«‹/æŠ€æœ¯æ´¾ (`@user_handle_3`)**: [è§‚ç‚¹é™ˆè¿°] [Source: T_c]
### åˆ†æå¸ˆç‚¹è¯„
[ä½ å¯¹è¿™åœºè¾©è®ºçš„æ€»ç»“ã€æ´å¯Ÿå’Œæ›´é«˜ç»´åº¦çš„ã€ç¯‡å¹…å……è¶³çš„åˆ†æ...]

---

## ä¸‰ã€è¶‹åŠ¿ä¸å™äº‹åˆ†æ
### 3.1 æ–°å…´è¶‹åŠ¿ï¼š[è¶‹åŠ¿åç§°]
[è¯¦ç»†æè¿°è¯¥è¶‹åŠ¿...] [Sources: T_d, T_e]
...(æ›´å¤šè¶‹åŠ¿)
### 3.2 å®å¤§å™äº‹ï¼š[å™äº‹åç§°]
[è¯¦ç»†æè¿°è¯¥å™äº‹...] [Sources: T_f, T_g]
...(æ›´å¤šå™äº‹)

---

## å››ã€ç²¾é€‰èµ„æºåº“
### 4.1 æ•™ç¨‹ä¸æŒ‡å—
*   **[èµ„æºåç§°]**: [è¯¦ç»†æ¨èç†ç”±] [Source: T_h]
*   ... (æ›´å¤šèµ„æº)
### 4.2 å·¥å…·ä¸é¡¹ç›®
*   **[èµ„æºåç§°]**: [è¯¦ç»†æ¨èç†ç”±] [Source: T_i]
*   ... (æ›´å¤šèµ„æº)

---

## äº”ã€è§’è‰²åŒ–è¡ŒåŠ¨å»ºè®®
*   **To å¼€å‘è€…**:
    * [å»ºè®®å†…å®¹] [Source: T_j]
    * ... (æ›´å¤šå»ºè®®)
*   **To äº§å“ç»ç†/åˆ›ä¸šè€…**:
    * [å»ºè®®å†…å®¹] [Source: T_k]
    * ... (æ›´å¤šå»ºè®®)
*   **To æŠ•èµ„è€…/ç ”ç©¶è€…**:
    * [å»ºè®®å†…å®¹] [Source: T_l]
    * ... (æ›´å¤šå»ºè®®)

# Input Data:
{formatted_context}
"""

        return prompt_template

    async def _generate_report_for_model(
        self,
        *,
        model_name: str,
        display_name: str,
        enriched_posts: List[Dict[str, Any]],
        context_md: str,
        sources: List[Dict[str, Any]],
        prompt: str,
        start_time: datetime,
        end_time: datetime
    ) -> Dict[str, Any]:
        """åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­ç”ŸæˆæŒ‡å®šæ¨¡å‹çš„æŠ¥å‘Š"""
        return await asyncio.to_thread(
            self._generate_report_for_model_sync,
            model_name,
            display_name,
            enriched_posts,
            context_md,
            sources,
            prompt,
            start_time,
            end_time
        )

    def _generate_report_for_model_sync(
        self,
        model_name: str,
        display_name: str,
        enriched_posts: List[Dict[str, Any]],
        context_md: str,
        sources: List[Dict[str, Any]],
        prompt: str,
        start_time: datetime,
        end_time: datetime
    ) -> Dict[str, Any]:
        """åŒæ­¥æ‰§è¡ŒæŒ‡å®šæ¨¡å‹çš„æŠ¥å‘Šç”Ÿæˆå’ŒNotionæ¨é€"""

        logger.info(f"[{display_name}] æ¨¡å‹çº¿ç¨‹å¯åŠ¨ï¼Œå¼€å§‹ç”Ÿæˆæƒ…æŠ¥æŠ¥å‘Š")

        # è°ƒç”¨LLMç”ŸæˆæŠ¥å‘Š
        try:
            response = self.llm_client.call_smart_model(prompt, model_override=model_name, temperature=0.4)

            if not response or not response.get('success'):
                error_msg = f"LLMè°ƒç”¨å¤±è´¥: {response.get('error') if response else 'Unknown error'}"
                logger.warning(f"[{display_name}] {error_msg}")
                return {
                    'success': False,
                    'error': error_msg,
                    'model': model_name,
                    'model_display': display_name
                }

            llm_output = response.get('content', '')
        except Exception as e:
            error_msg = f"LLMè°ƒç”¨å¼‚å¸¸: {str(e)}"
            logger.error(f"[{display_name}] {error_msg}")
            return {
                'success': False,
                'error': error_msg,
                'model': model_name,
                'model_display': display_name
            }

        # ä¸ºLLMç”Ÿæˆçš„æŠ¥å‘Šæ·»åŠ æ ‡å‡†å¤´éƒ¨ä¿¡æ¯
        beijing_time = self._bj_time()
        header_info = [
            f"# ğŸ“Š X/Twitter æŠ€æœ¯æƒ…æŠ¥æ—¥æŠ¥ - {display_name}",
            "",
            f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {beijing_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
            "",
            f"*æ•°æ®èŒƒå›´: {start_time.strftime('%Y-%m-%d %H:%M:%S')} - {end_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
            "",
            f"*åˆ†æåŠ¨æ€æ•°: {len(enriched_posts)} æ¡*",
            "",
            "---",
            ""
        ]

        # æ¸…ç†LLMè¾“å‡ºä¸­å¯èƒ½çš„æ ¼å¼é—®é¢˜
        cleaned_llm_output = self._clean_llm_output_for_notion(llm_output)

        sources_section = self._render_sources_section(sources)

        # æ„å»ºæŠ¥å‘Šå°¾éƒ¨
        footer_lines = ["", "---", ""]
        provider = response.get('provider')
        model = response.get('model')
        if provider:
            footer_lines.append(f"*åˆ†æå¼•æ“: {provider} ({model or 'unknown'})*")

        footer_lines.extend([
            "",
            f"ğŸ“Š **ç»Ÿè®¡æ‘˜è¦**: æœ¬æŠ¥å‘Šåˆ†æäº† {len(enriched_posts)} æ¡åŠ¨æ€",
            "",
            "*æœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ*"
        ])
        footer_section = "\n".join(footer_lines)

        report_content = "\n".join(header_info) + cleaned_llm_output + "\n\n" + sources_section + footer_section

        # åº”ç”¨æ¥æºé“¾æ¥å¢å¼ºåå¤„ç†
        report_content = self._enhance_source_links(report_content, sources)

        title = f"X/Twitter æŠ€æœ¯æƒ…æŠ¥æ—¥æŠ¥ - {display_name} - {end_time.strftime('%Y-%m-%d %H:%M')}"

        # ä¿å­˜æŠ¥å‘Šåˆ°æ•°æ®åº“
        try:
            if self.db_manager.save_intelligence_report(
                'daily',
                title,
                report_content,
                start_time,
                end_time
            ):
                logger.info(f"[{display_name}] æƒ…æŠ¥æŠ¥å‘Šå·²æˆåŠŸä¿å­˜åˆ°æ•°æ®åº“")
            else:
                logger.warning(f"[{display_name}] æŠ¥å‘Šä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥")
        except Exception as e:
            logger.error(f"[{display_name}] ä¿å­˜æŠ¥å‘Šåˆ°æ•°æ®åº“æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")

        model_report = {
            'model': model_name,
            'model_display': display_name,
            'success': True,
            'report_title': title,
            'report_content': report_content,
            'provider': response.get('provider') if response else None,
            'items_analyzed': len(enriched_posts)
        }

        # å°è¯•æ¨é€åˆ°Notion
        notion_push_info = None
        try:
            # æ ¼å¼åŒ–Notionæ ‡é¢˜
            beijing_time = self._bj_time()
            time_str = beijing_time.strftime('%H:%M')
            notion_title = f"[{time_str}] [{display_name}] XæŠ€æœ¯æƒ…æŠ¥æ—¥æŠ¥ ({len(enriched_posts)}æ¡åŠ¨æ€)"

            logger.info(f"å¼€å§‹æ¨é€æƒ…æŠ¥æŠ¥å‘Šåˆ°Notion ({display_name}): {notion_title}")

            notion_result = x_intelligence_notion_client.create_report_page(
                report_title=notion_title,
                report_content=report_content,
                report_date=beijing_time
            )

            if notion_result.get('success'):
                logger.info(f"æƒ…æŠ¥æŠ¥å‘ŠæˆåŠŸæ¨é€åˆ°Notion ({display_name}): {notion_result.get('page_url')}")
                notion_push_info = {
                    'success': True,
                    'page_url': notion_result.get('page_url'),
                    'path': notion_result.get('path')
                }
            else:
                error_msg = notion_result.get('error', 'æœªçŸ¥é”™è¯¯')
                logger.warning(f"æ¨é€æƒ…æŠ¥æŠ¥å‘Šåˆ°Notionå¤±è´¥ ({display_name}): {error_msg}")
                notion_push_info = {
                    'success': False,
                    'error': error_msg
                }

        except Exception as e:
            logger.warning(f"æ¨é€æƒ…æŠ¥æŠ¥å‘Šåˆ°Notionæ—¶å‡ºé”™ ({display_name}): {e}")
            notion_push_info = {
                'success': False,
                'error': str(e)
            }

        if notion_push_info:
            model_report['notion_push'] = notion_push_info

        return model_report

    def _clean_llm_output_for_notion(self, llm_output: str) -> str:
        """æ¸…ç†LLMè¾“å‡ºå†…å®¹ï¼Œç¡®ä¿Notionå…¼å®¹æ€§"""
        if not llm_output:
            return ""

        # ä¿æŠ¤Sourceå¼•ç”¨æ ¼å¼ï¼Œä¸è¦æ›¿æ¢å…¶ä¸­çš„æ–¹æ‹¬å·
        import re

        # å…ˆæå–æ‰€æœ‰Sourceå¼•ç”¨
        source_pattern = r'\[Sources?:\s*[T\d\s,]+\]'
        sources = re.findall(source_pattern, llm_output)

        # ä¸´æ—¶æ›¿æ¢Sourceå¼•ç”¨ä¸ºå ä½ç¬¦
        temp_llm_output = llm_output
        source_placeholders = {}
        for i, source in enumerate(sources):
            placeholder = f"__SOURCE_PLACEHOLDER_{i}__"
            source_placeholders[placeholder] = source
            temp_llm_output = temp_llm_output.replace(source, placeholder)

        # æ›¿æ¢å…¶ä»–å¯èƒ½å¯¼è‡´Markdowné“¾æ¥å†²çªçš„æ–¹æ‹¬å·
        cleaned = temp_llm_output.replace('[', 'ã€').replace(']', 'ã€‘')

        # æ¢å¤Sourceå¼•ç”¨
        for placeholder, original_source in source_placeholders.items():
            cleaned = cleaned.replace(placeholder, original_source)

        # ç¡®ä¿è¡Œå°¾æœ‰é€‚å½“çš„ç©ºæ ¼ç”¨äºæ¢è¡Œ
        lines = cleaned.split('\n')
        processed_lines = []

        for line in lines:
            # å¯¹äºä»¥*å¼€å¤´çš„æ–œä½“è¡Œï¼Œåœ¨è¡Œå°¾æ·»åŠ ç©ºæ ¼ä»¥ç¡®ä¿æ¢è¡Œ
            if line.strip().startswith('*') and line.strip().endswith('*'):
                processed_lines.append(line.rstrip() + '  ')
            else:
                processed_lines.append(line)

        return '\n'.join(processed_lines)

    def _render_sources_section(self, sources: List[Dict[str, Any]]) -> str:
        """æ¸²æŸ“æ¥æºæ¸…å•éƒ¨åˆ†"""
        if not sources:
            return ""

        lines = ["## ğŸ“š æ¥æºæ¸…å• (Source List)", ""]
        for s in sources:
            # æ¸…ç†æ ‡é¢˜ä¸­çš„æ–¹æ‹¬å·ï¼Œé¿å…ä¸Markdowné“¾æ¥å†²çª
            clean_title = (s.get('title') or s.get('excerpt') or '').replace('[', 'ã€').replace(']', 'ã€‘')
            nickname = s.get('nickname') or ''
            if nickname:
                nickname_display = f"@{nickname}"
            else:
                nickname_display = ""

            link = s.get('link')
            if link:
                actor_part = f"[{nickname_display}]({link})" if nickname_display else f"[æ¥æº]({link})"
            else:
                actor_part = nickname_display or "æ¥æº"

            lines.append(f"- **ã€{s.get('sid')}ã€‘**: {actor_part}: {clean_title}")
        return "\n".join(lines)

    def _enhance_source_links(self, report_content: str, sources: List[Dict[str, Any]]) -> str:
        """
        å¢å¼ºæŠ¥å‘Šä¸­çš„æ¥æºé“¾æ¥ï¼Œå°† [Source: T1, T2] ä¸­çš„æ¯ä¸ª Txx è½¬æ¢ä¸ºå¯ç‚¹å‡»çš„é“¾æ¥
        """
        import re

        # æ„å»ºæ¥æºIDåˆ°é“¾æ¥çš„æ˜ å°„
        source_link_map = {s['sid']: s['link'] for s in sources}

        def replace_source_refs(match):
            # æå–å®Œæ•´çš„ Source å¼•ç”¨å†…å®¹
            full_source_text = match.group(0)  # å¦‚ "[Source: T2, T9, T18]"
            source_content = match.group(1)    # å¦‚ "T2, T9, T18"

            # åˆ†å‰²å¹¶å¤„ç†æ¯ä¸ªæ¥æºID
            source_ids = [sid.strip() for sid in source_content.split(',')]
            linked_sources = []

            for sid in source_ids:
                if sid in source_link_map:
                    # å°† Txx è½¬æ¢ä¸ºé“¾æ¥
                    linked_sources.append(f"[{sid}]({source_link_map[sid]})")
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°å¯¹åº”é“¾æ¥ï¼Œä¿æŒåŸæ ·
                    linked_sources.append(sid)

            # é‡æ–°ç»„åˆ
            return f"ğŸ“ [Source: {', '.join(linked_sources)}]"

        # æŸ¥æ‰¾æ‰€æœ‰ [Source: ...] æˆ– [Sources: ...] æ¨¡å¼å¹¶æ›¿æ¢
        pattern = r'\[Sources?:\s*([T\d\s,]+)\]'
        enhanced_content = re.sub(pattern, replace_source_refs, report_content)

        return enhanced_content

    async def generate_intelligence_report(self, hours: int = 24, limit: int = 300) -> Dict[str, Any]:
        """
        ç”Ÿæˆæƒ…æŠ¥åˆ†ææŠ¥å‘Šï¼Œæ”¯æŒå¤šæ¨¡å‹å¹¶è¡Œç”Ÿæˆ

        Args:
            hours: æ—¶é—´èŒƒå›´ï¼ˆå°æ—¶ï¼‰
            limit: æœ€å¤§å¸–å­æ•°é‡

        Returns:
            ç”Ÿæˆç»“æœ
        """
        self._log_task_start("æƒ…æŠ¥æŠ¥å‘Šç”Ÿæˆ", hours=hours, limit=limit)

        try:
            # è®¡ç®—æ—¶é—´èŒƒå›´
            end_time = datetime.now()
            start_time = end_time - timedelta(hours=hours)

            # è·å–å¯ŒåŒ–åçš„å¸–å­æ•°æ®
            enriched_posts = self.db_manager.get_enriched_posts_for_report(
                start_time, end_time, limit
            )

            if not enriched_posts:
                logger.warning(f"åœ¨æŒ‡å®šæ—¶é—´èŒƒå›´å†…æ²¡æœ‰æ‰¾åˆ°å¯ŒåŒ–çš„å¸–å­æ•°æ®")
                return self._create_error_response('æ²¡æœ‰å¯ç”¨çš„å¸–å­æ•°æ®')

            logger.info(f"è·å–åˆ° {len(enriched_posts)} æ¡å¯ŒåŒ–å¸–å­æ•°æ®")

            # æ ¼å¼åŒ–ä¸Šä¸‹æ–‡
            formatted_context, sources = self.format_enriched_posts_for_smart_llm(enriched_posts)

            # æ„å»ºæç¤ºè¯
            time_range_str = f"è¿‡å»{hours}å°æ—¶"
            prompt = self.get_intelligence_report_prompt(formatted_context, time_range_str)

            logger.info(f"æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")

            # è·å–è¦ä½¿ç”¨çš„æ¨¡å‹åˆ—è¡¨
            models_to_generate = self._get_report_models()
            if not models_to_generate:
                logger.warning("æœªé…ç½®ä»»ä½•å¯ç”¨äºç”ŸæˆæŠ¥å‘Šçš„æ¨¡å‹")
                return self._create_error_response('æœªé…ç½®å¯ç”¨çš„LLMæ¨¡å‹')

            model_reports: List[Dict[str, Any]] = []
            failures: List[Dict[str, Any]] = []
            tasks = []
            task_meta: List[Dict[str, str]] = []

            # ä¸ºæ¯ä¸ªæ¨¡å‹åˆ›å»ºå¹¶è¡Œä»»åŠ¡
            for model_name in models_to_generate:
                display_name = self._get_model_display_name(model_name)
                task_meta.append({'model': model_name, 'display': display_name})
                tasks.append(
                    self._generate_report_for_model(
                        model_name=model_name,
                        display_name=display_name,
                        enriched_posts=enriched_posts,
                        context_md=formatted_context,
                        sources=sources,
                        prompt=prompt,
                        start_time=start_time,
                        end_time=end_time
                    )
                )

            logger.info(
                f"å¼€å§‹å¹¶è¡Œç”Ÿæˆ {len(tasks)} ä»½æƒ…æŠ¥æŠ¥å‘Š: {[meta['display'] for meta in task_meta]}"
            )

            # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
            task_results = await asyncio.gather(*tasks, return_exceptions=True)

            # å¤„ç†ä»»åŠ¡ç»“æœ
            for meta, task_result in zip(task_meta, task_results):
                model_name = meta['model']
                display_name = meta['display']

                if isinstance(task_result, Exception):
                    error_msg = str(task_result)
                    logger.warning(
                        f"æ¨¡å‹ {model_name} ({display_name}) æŠ¥å‘Šç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°æœªå¤„ç†å¼‚å¸¸: {error_msg}"
                    )
                    failures.append({
                        'model': model_name,
                        'model_display': display_name,
                        'error': error_msg
                    })
                    continue

                if task_result.get('success'):
                    model_reports.append(task_result)
                else:
                    failure_entry = {
                        'model': model_name,
                        'model_display': display_name,
                        'error': task_result.get('error', 'æŠ¥å‘Šç”Ÿæˆå¤±è´¥')
                    }
                    failures.append(failure_entry)

            # æ„å»ºæœ€ç»ˆç»“æœ
            overall_success = len(model_reports) > 0
            result = {
                'success': overall_success,
                'items_analyzed': len(enriched_posts) if overall_success else 0,
                'model_reports': model_reports,
                'failures': failures
            }

            if overall_success:
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªæˆåŠŸçš„æŠ¥å‘Šä½œä¸ºä¸»è¦ç»“æœ
                primary_report = model_reports[0]
                result['report_title'] = primary_report['report_title']
                result['report_content'] = primary_report['report_content']
                result['notion_push'] = primary_report.get('notion_push')
                result['time_range'] = f"{start_time.strftime('%Y-%m-%d %H:%M')} - {end_time.strftime('%Y-%m-%d %H:%M')}"

            self._log_task_complete(
                "æƒ…æŠ¥æŠ¥å‘Šç”Ÿæˆ",
                len(model_reports),
                len(failures),
                models=len(models_to_generate)
            )

            return result

        except Exception as e:
            logger.error(f"ç”Ÿæˆæƒ…æŠ¥æŠ¥å‘Šæ—¶å‘ç”Ÿå¼‚å¸¸: {e}", exc_info=True)
            return self._create_error_response(f'ç”Ÿæˆå¼‚å¸¸: {str(e)}')

    def generate_kol_report(self, user_id: int, days: int = 30) -> Dict[str, Any]:
        """
        ç”ŸæˆKOLæ€æƒ³è½¨è¿¹æŠ¥å‘Š

        Args:
            user_id: ç”¨æˆ·ID
            days: åˆ†æå¤©æ•°

        Returns:
            ç”Ÿæˆç»“æœ
        """
        logger.info(f"å¼€å§‹ç”ŸæˆKOLæŠ¥å‘Šï¼Œç”¨æˆ·ID: {user_id}ï¼Œå¤©æ•°: {days}")

        try:
            # è·å–ç”¨æˆ·ä¿¡æ¯
            with self.db_manager.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT user_id FROM twitter_users WHERE id = %s", (user_id,))
                result = cursor.fetchone()
                if not result:
                    return {'success': False, 'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}
                user_handle = result[0]

            # è·å–ç”¨æˆ·æ¡£æ¡ˆ
            with self.db_manager.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute(
                    "SELECT profile_data FROM twitter_user_profiles WHERE user_table_id = %s",
                    (user_id,)
                )
                profile_result = cursor.fetchone()
                if not profile_result:
                    return {'success': False, 'error': 'ç”¨æˆ·æ¡£æ¡ˆä¸å­˜åœ¨'}

                user_profile_json = profile_result[0]

            # è·å–ç”¨æˆ·çš„å¯ŒåŒ–å¸–å­æ•°æ®
            enriched_posts = self.db_manager.get_user_enriched_posts(user_id, days)

            if not enriched_posts:
                return {'success': False, 'error': 'æ²¡æœ‰å¯ç”¨çš„å¸–å­æ•°æ®'}

            # æ ¼å¼åŒ–ç”¨æˆ·å¸–å­åˆé›†
            user_posts_collection = self._format_user_posts_for_kol_report(enriched_posts)

            # æ„å»ºKOLæŠ¥å‘Šæç¤ºè¯
            kol_prompt = self.get_kol_report_prompt(user_profile_json, user_posts_collection, user_handle)

            # è°ƒç”¨Smart LLMç”ŸæˆæŠ¥å‘Š
            response = self.llm_client.call_smart_model(kol_prompt, temperature=0.3)

            if not response['success']:
                return {'success': False, 'error': response.get('error')}

            report_content = response['content']
            report_title = f"@{user_handle} æ€æƒ³è½¨è¿¹æœˆåº¦æŠ¥å‘Š - {datetime.now().strftime('%Y-%m-%d')}"

            # ä¿å­˜æŠ¥å‘Š
            if self.db_manager.save_intelligence_report(
                'monthly_kol',
                report_title,
                report_content,
                related_user_id=user_id
            ):
                return {
                    'success': True,
                    'report_title': report_title,
                    'report_content': report_content,
                    'user_handle': user_handle
                }
            else:
                return {'success': False, 'error': 'æŠ¥å‘Šä¿å­˜å¤±è´¥', 'report_content': report_content}

        except Exception as e:
            logger.error(f"ç”ŸæˆKOLæŠ¥å‘Šæ—¶å‘ç”Ÿå¼‚å¸¸: {e}", exc_info=True)
            return {'success': False, 'error': str(e)}

    def _format_user_posts_for_kol_report(self, posts: List[Dict[str, Any]]) -> str:
        """ä¸ºKOLæŠ¥å‘Šæ ¼å¼åŒ–ç”¨æˆ·å¸–å­æ•°æ®"""
        formatted_posts = []
        for i, post in enumerate(posts, 1):
            published_at = post.get('published_at')
            time_str = published_at.strftime('%Y-%m-%d') if published_at else 'æœªçŸ¥æ—¥æœŸ'

            post_info = f"[T_{i}] [{time_str}] [{post.get('content_type', 'æœªçŸ¥ç±»å‹')}] [{post.get('post_tag', 'æ— æ ‡ç­¾')}] {post.get('post_content', '')}"
            formatted_posts.append(post_info)

        return '\n'.join(formatted_posts)

    def get_kol_report_prompt(self, user_profile_json: str, user_posts_collection: str, user_handle: str) -> str:
        """æ„å»ºKOLæŠ¥å‘Šæç¤ºè¯"""
        return f"""# Role: èµ„æ·±äººç‰©åˆ†æå¸ˆä¸ä¼ è®°ä½œå®¶

# Context:
ä½ æ­£åœ¨ä¸ºä¸€ä½é‡è¦çš„æŠ€æœ¯é¢†è¢–æ’°å†™ä¸€ä»½ç§å¯†çš„æœˆåº¦æ€æƒ³çºªè¦ã€‚ä½ çš„ä»»åŠ¡æ˜¯é€šè¯»ä»–/å¥¹æœ¬æœˆå‘å¸ƒçš„æ‰€æœ‰å¸–å­åŠå…¶æ•°å­—æ¡£æ¡ˆï¼Œæ¢³ç†å‡ºå…¶æ€æƒ³è„‰ç»œã€å…³æ³¨ç‚¹å˜åŒ–å’Œæ ¸å¿ƒæ´å¯Ÿã€‚

# Core Principles:
1.  **æ´å¯Ÿå…¶å˜ (Perceive the Change)**: ä½ çš„æ ¸å¿ƒæ˜¯å‘ç°"å˜åŒ–"ã€‚ä»–/å¥¹çš„å…³æ³¨ç‚¹ä»å“ªé‡Œè½¬ç§»åˆ°äº†å“ªé‡Œï¼Ÿå¯¹æŸä¸ªé—®é¢˜çš„çœ‹æ³•æ˜¯å¦å‘ç”Ÿäº†æ”¹å˜ï¼Ÿ
2.  **æŠ“ä½ç²¾é«“ (Capture the Essence)**: ä¸è¦æµæ°´è´¦ã€‚ä½ éœ€è¦æç‚¼å‡ºä»–/å¥¹æœ¬æœˆæœ€é—ªå…‰çš„ã€æœ€å…·ä»£è¡¨æ€§çš„è§‚ç‚¹å’Œåˆ†äº«ã€‚
3.  **å®¢è§‚ä¸­ç«‹ (Stay Objective)**: ä½ çš„åˆ†æåº”åŸºäºåŸæ–‡ï¼Œé¿å…è¿‡åº¦è§£è¯»å’Œä¸»è§‚è‡†æ–­ã€‚

# Input Data:
1.  **ç”¨æˆ·æ•°å­—æ¡£æ¡ˆ**:
    '''
    {user_profile_json}
    '''
2.  **æœ¬æœˆè¨€è®ºåˆé›†**:
    '''
    {user_posts_collection}
    '''

# Your Task:
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ç»“æ„ï¼Œç”Ÿæˆä¸€ä»½å…³äº @{user_handle} çš„æœˆåº¦æ€æƒ³è½¨è¿¹æŠ¥å‘Šã€‚

## 1. æœ¬æœˆæ ¸å¿ƒå…³æ³¨ç‚¹
*   **é¢†åŸŸA**: [æè¿°...]
*   **é¢†åŸŸB**: [æè¿°...]

---

## 2. å…³é”®è§‚ç‚¹ä¸ç«‹åœºæ¼”å˜
### 2.1 æœ¬æœˆé‡‘å¥
> [å¼•ç”¨çš„"é‡‘å¥"]
*   **è§£è¯»**: [ä½ å¯¹æ­¤å¥è¯çš„è§£è¯»...]
### 2.2 ç«‹åœºåˆ†æ (å¯é€‰)
*   å…³äº"[è¯é¢˜]"çš„è§‚ç‚¹ï¼Œä»[æ—§è§‚ç‚¹]æ¼”å˜ä¸º[æ–°è§‚ç‚¹]ï¼Œä¸»è¦ä½“ç°åœ¨...

---

## 3. é«˜ä»·å€¼åˆ†äº«ä¸ç½‘ç»œäº’åŠ¨
### 3.1 é«˜ä»·å€¼åˆ†äº«
*   **[é¡¹ç›®/æ–‡ç« A]**: [ä»·å€¼è¯´æ˜] [Source: T_n]
*   **[é¡¹ç›®/æ–‡ç« B]**: [ä»·å€¼è¯´æ˜] [Source: T_m]
### 3.2 æ ¸å¿ƒäº’åŠ¨
*   æœ¬æœˆä¸ `@user_handle` çš„å…³äº [è¯é¢˜] çš„è®¨è®ºå€¼å¾—å…³æ³¨ï¼Œæ­ç¤ºäº†...

---

## 4. æ€æƒ³è½¨è¿¹æ€»ç»“
[æ€»ç»“å†…å®¹...]"""


def run_daily_intelligence_report(hours: int = 24, limit: int = 300) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•°ï¼šè¿è¡Œæ—¥åº¦æƒ…æŠ¥æŠ¥å‘Šç”Ÿæˆ

    Args:
        hours: æ—¶é—´èŒƒå›´ï¼ˆå°æ—¶ï¼‰
        limit: æœ€å¤§å¸–å­æ•°é‡

    Returns:
        ç”Ÿæˆç»“æœ
    """
    generator = IntelligenceReportGenerator()
    return asyncio.run(generator.generate_intelligence_report(hours, limit))


def run_kol_report(user_id: int, days: int = 30) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•°ï¼šè¿è¡ŒKOLæŠ¥å‘Šç”Ÿæˆ

    Args:
        user_id: ç”¨æˆ·ID
        days: åˆ†æå¤©æ•°

    Returns:
        ç”Ÿæˆç»“æœ
    """
    generator = IntelligenceReportGenerator()
    return generator.generate_kol_report(user_id, days)
